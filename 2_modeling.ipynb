{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a118f9d",
   "metadata": {},
   "source": [
    "## 딥러닝 학습\n",
    "Seq2Seq 선택\n",
    "\n",
    "+ RNN의 경우 문장이 길어질수록 앞의 정보가 뒤로 충분히 전달되지 못하기 때문에, 최대 길이가 100글자가 넘는 문장을 처리하기에 부적합\n",
    "+ RNN기반인 LSTM, GRU 또한 이런 장기의존성 문제를 갖고 있음  \n",
    "    => 인코더-디코더를 이용해 장기의존성 문제를 해결한 Attention 모델 활용  \n",
    "    => Seq2Seq는 2014년 발표되어 챗봇과 기계번역에 많이 쓰이는 모델로,  \n",
    "        입력 시퀀스와 출력 시퀀스를 각각 입력 문장과 번역 문장으로 만들면 번역기를 만들 수 있을 것으로 예상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d0bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8f1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, re, jieba\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, save_model, load_model\n",
    "from keras.layers import Input, LSTM, Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65d501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow GPU 사용방법 참고)https://github.com/tensorflow/docs-l10n/blob/master/site/ko/guide/gpu.ipynb \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print('GPU running')\n",
    "  except RuntimeError as e:\n",
    "    print('Runtime Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed9477",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1ced9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(language):\n",
    "    lang_tokenizer = Tokenizer(filters=' ')\n",
    "    lang_tokenizer.fit_on_texts(language)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(language)\n",
    "    tensor = pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9c5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1_preprocessing.ipynb에서 만들었던 함수 활용\n",
    "def preprocess_ch(w):\n",
    "    w = ' '.join(jieba.cut(w, cut_all=False))   \n",
    "    w = w.rstrip().strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "#한국어 전처리\n",
    "def preprocess_kr(w):\n",
    "    w = w.strip()\n",
    "    w = re.sub(r\"([?.'!,¿\\\"])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[ |ㄱ-ㅎ|ㅏ-ㅣ]+', \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w  \n",
    "\n",
    "def preprocess(path):\n",
    "    files = glob.glob(os.path.join(path, '*.csv'))\n",
    "    ch, ko = [], []\n",
    "    \n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    "        ch.extend(df['중국어'].values)\n",
    "        ko.extend(df['한국어'].values)\n",
    "    \n",
    "    ch_series = pd.Series(ch)\n",
    "    ko_series = pd.Series(ko)\n",
    "    \n",
    "    df = pd.concat([ch_series, ko_series], axis=1)\n",
    "    df.columns = ['중국어', '한국어']\n",
    "    \n",
    "    df['중국어'] = df['중국어'].apply(preprocess_ch)\n",
    "    df['한국어'] = df['한국어'].apply(preprocess_kr)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def tokenize_dataset(num_data):  #원래 path를 인자로 넘기려 했으나, 용량문제 해결 위해 num_data 사용\n",
    "    df = pd.read_csv('train_df.csv', index_col=0)\n",
    "    df = df.sample(num_data, random_state=2)\n",
    "    ch_tensor, ch_tokenizer = tokenize(df['중국어'].values)\n",
    "    ko_tensor, ko_tokenizer = tokenize(df['한국어'].values)\n",
    "    return ch_tensor, ch_tokenizer, ko_tensor, ko_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebd6f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 90), (10000, 54))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_tensor, ch_tokenizer, ko_tensor, ko_tokenizer = tokenize_dataset(10000)\n",
    "\n",
    "print(ch_tensor.shape, ko_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa142f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 54\n",
      "8000 2000\n",
      "8000 2000\n"
     ]
    }
   ],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "max_length_ch, max_length_ko = max_length(ch_tensor), max_length(ko_tensor)\n",
    "print(max_length_ch, max_length_ko)\n",
    "\n",
    "ch_tensor_train, ch_tensor_val, ko_tensor_train, ko_tensor_val = train_test_split(ch_tensor, ko_tensor, test_size=0.2)\n",
    "print(len(ch_tensor_train), len(ch_tensor_val))\n",
    "print(len(ko_tensor_train), len(ko_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea47e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(tokenizer, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print(\"%d ----> %s\" % (t, tokenizer.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770bcbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "3 ----> <start>\n",
      "1850 ----> 反而\n",
      "11 ----> 是\n",
      "3544 ----> 超出\n",
      "470 ----> 必要\n",
      "385 ----> 范围\n",
      "1 ----> 的\n",
      "9108 ----> 多巴胺\n",
      "557 ----> 引起\n",
      "1 ----> 的\n",
      "1518 ----> 不安\n",
      "10 ----> 和\n",
      "2947 ----> 动摇\n",
      "4934 ----> 只会\n",
      "276 ----> 使\n",
      "3553 ----> 能量\n",
      "861 ----> 迅速\n",
      "5877 ----> 燃烧\n",
      "5 ----> 。\n",
      "4 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "1073 ----> 오히려\n",
      "2170 ----> 필요\n",
      "293 ----> 이상의\n",
      "57327 ----> 도파민이\n",
      "57328 ----> 불러오는\n",
      "57329 ----> 불안과\n",
      "57330 ----> 동요는\n",
      "4652 ----> 에너지를\n",
      "657 ----> 빠르게\n",
      "57331 ----> 연소시킬\n",
      "3016 ----> 뿐이다\n",
      "1 ----> .\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Language; index to word mapping\")\n",
    "convert(ch_tokenizer, ch_tensor_train[0])\n",
    "print()\n",
    "print(\"Target Language; index to word mapping\")\n",
    "convert(ko_tokenizer, ko_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d557541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(ch_tensor_train)\n",
    "BATCH_SIZE = 2\n",
    "steps_per_epoch = len(ch_tensor_train) // BATCH_SIZE\n",
    "embedding_size = 256\n",
    "units = 1024\n",
    "vocab_input_size = len(ch_tokenizer.word_index)   #중국어 토큰 개수(47066)\n",
    "vocab_target_size = len(ko_tokenizer.word_index)  #한국어 토큰 개수(274429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcf4768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (ch_tensor_train, ko_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "304120d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 90) (2, 54)\n"
     ]
    }
   ],
   "source": [
    "example_input_batch, example_targ_batch = next(iter(dataset))\n",
    "print(example_input_batch.shape, example_targ_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e5018",
   "metadata": {},
   "source": [
    "### 인코더 모델 생성\n",
    "+ input(중국어) => [batch_size, max_length_inp]\n",
    "+ 임베딩 층 => [batch_size,max_length_inp, embedding_dim]\n",
    "+ GRU 층 => output(한국어)[batch_size, max_length_inp, enc_units],  \n",
    "                히든레이어[batch_size, enc_units]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ebc38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33362e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output (batch size, sequence length, units) = (2, 90, 1024)\n",
      "Encoder Hidden state  (batch size, units) = (2, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_input_size, embedding_size, units, BATCH_SIZE)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "\n",
    "print(f'Encoder output (batch size, sequence length, units) = {sample_output.shape}')   \n",
    "print(f'Encoder Hidden state  (batch size, units) = {sample_hidden.shape}')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae78ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "703ccb7a",
   "metadata": {},
   "source": [
    "### Attention 매커니즘\n",
    "+ output [batch_size, max_length_inp, enc_units] => values 로 사용\n",
    "+ 히든레이어 [batch_size, enc_units] => query 로 사용\n",
    "+ (참고)https://hcnoh.github.io/2018-12-11-bahdanau-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c382368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        # [batch_size, 1, enc_units]\n",
    "\n",
    "        score = self.V(\n",
    "            tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        # [batch_size, mex_length_inp, 1]\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # [batch_size, mex_length_inp, 1]\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        # [batch_size, max_length_inp, enc_units]\n",
    "\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        # [batch_size, enc_units]\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2429db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (2, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (2, 90, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(f\"Attention result shape: (batch size, units) {attention_result.shape}\")\n",
    "print(f\"Attention weights shape: (batch_size, sequence_length, 1) {attention_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b93a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a16c0124",
   "metadata": {},
   "source": [
    "### 디코더 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8648fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # 단어 하나하나 해석 진행 \n",
    "        # x: [batch_size, 1],\n",
    "        # hidden: [batch_size, units]\n",
    "        # enc_output: [batch_size, max_length_inp, enc_units]\n",
    "\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # [batch_size, enc_units]，[batch_size, max_length_inp, 1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        # [batch_size, 1, embedding_dim+enc_units]\n",
    "\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62d1f9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (2, 64511)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_target_size, embedding_size, units, BATCH_SIZE)\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
    "\n",
    "print(f'Decoder output shape: (batch_size, vocab size) {sample_decoder_output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef40c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c28f104",
   "metadata": {},
   "source": [
    "### optimizer, 손실함수 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a36269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_objects = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                             reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    # 0이면 False, 그 외는 True로 처리\n",
    "    # 데이터 벡터화하면서 모두 뒷부분에 0을 붙여 동일한 길이가 되도록 마스킹\n",
    "    \n",
    "    loss_ = loss_objects(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b88fa70",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0da56d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../checkpoint/ch_to_ko_attention'\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"cpkt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, \n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_dir,\n",
    "                                     checkpoint_name='model.ckpt',\n",
    "                                     max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea90dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([ko_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden,\n",
    "                                                 enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2f8237b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.999214\n",
      "Epoch 1 Loss 0.0010\n",
      "Time taken for 1 epoch 64.46890091896057 sec\n",
      "\n",
      "Epoch 1 Loss 0.0019\n",
      "Time taken for 1 epoch 78.56889963150024 sec\n",
      "\n",
      "Epoch 1 Loss 0.0027\n",
      "Time taken for 1 epoch 92.1432614326477 sec\n",
      "\n",
      "Epoch 1 Loss 0.0038\n",
      "Time taken for 1 epoch 106.45506596565247 sec\n",
      "\n",
      "Epoch 1 Loss 0.0046\n",
      "Time taken for 1 epoch 119.64306831359863 sec\n",
      "\n",
      "Epoch 1 Loss 0.0058\n",
      "Time taken for 1 epoch 135.2016031742096 sec\n",
      "\n",
      "Epoch 1 Loss 0.0065\n",
      "Time taken for 1 epoch 148.17160320281982 sec\n",
      "\n",
      "Epoch 1 Loss 0.0072\n",
      "Time taken for 1 epoch 162.9225480556488 sec\n",
      "\n",
      "Epoch 1 Loss 0.0081\n",
      "Time taken for 1 epoch 177.35154843330383 sec\n",
      "\n",
      "Epoch 1 Loss 0.0089\n",
      "Time taken for 1 epoch 193.4756829738617 sec\n",
      "\n",
      "Epoch 1 Loss 0.0099\n",
      "Time taken for 1 epoch 208.7083432674408 sec\n",
      "\n",
      "Epoch 1 Loss 0.0110\n",
      "Time taken for 1 epoch 224.88794326782227 sec\n",
      "\n",
      "Epoch 1 Loss 0.0117\n",
      "Time taken for 1 epoch 237.90194272994995 sec\n",
      "\n",
      "Epoch 1 Loss 0.0125\n",
      "Time taken for 1 epoch 251.80194282531738 sec\n",
      "\n",
      "Epoch 1 Loss 0.0131\n",
      "Time taken for 1 epoch 265.5785279273987 sec\n",
      "\n",
      "Epoch 1 Loss 0.0141\n",
      "Time taken for 1 epoch 278.93199610710144 sec\n",
      "\n",
      "Epoch 1 Loss 0.0150\n",
      "Time taken for 1 epoch 293.6945765018463 sec\n",
      "\n",
      "Epoch 1 Loss 0.0163\n",
      "Time taken for 1 epoch 308.73459243774414 sec\n",
      "\n",
      "Epoch 1 Loss 0.0171\n",
      "Time taken for 1 epoch 323.9356451034546 sec\n",
      "\n",
      "Epoch 1 Loss 0.0181\n",
      "Time taken for 1 epoch 339.1481730937958 sec\n",
      "\n",
      "Epoch 1 Loss 0.0192\n",
      "Time taken for 1 epoch 355.8601727485657 sec\n",
      "\n",
      "Epoch 1 Loss 0.0201\n",
      "Time taken for 1 epoch 376.1824595928192 sec\n",
      "\n",
      "Epoch 1 Loss 0.0209\n",
      "Time taken for 1 epoch 388.4318280220032 sec\n",
      "\n",
      "Epoch 1 Loss 0.0221\n",
      "Time taken for 1 epoch 403.4693229198456 sec\n",
      "\n",
      "Epoch 1 Loss 0.0228\n",
      "Time taken for 1 epoch 419.2983236312866 sec\n",
      "\n",
      "Epoch 1 Loss 0.0236\n",
      "Time taken for 1 epoch 434.2746772766113 sec\n",
      "\n",
      "Epoch 1 Loss 0.0245\n",
      "Time taken for 1 epoch 451.20667719841003 sec\n",
      "\n",
      "Epoch 1 Loss 0.0252\n",
      "Time taken for 1 epoch 471.3847017288208 sec\n",
      "\n",
      "Epoch 1 Loss 0.0262\n",
      "Time taken for 1 epoch 489.4857008457184 sec\n",
      "\n",
      "Epoch 1 Loss 0.0272\n",
      "Time taken for 1 epoch 503.936870098114 sec\n",
      "\n",
      "Epoch 1 Loss 0.0280\n",
      "Time taken for 1 epoch 519.4738683700562 sec\n",
      "\n",
      "Epoch 1 Loss 0.0291\n",
      "Time taken for 1 epoch 535.013689994812 sec\n",
      "\n",
      "Epoch 1 Loss 0.0300\n",
      "Time taken for 1 epoch 550.1036903858185 sec\n",
      "\n",
      "Epoch 1 Loss 0.0310\n",
      "Time taken for 1 epoch 564.3896782398224 sec\n",
      "\n",
      "Epoch 1 Loss 0.0317\n",
      "Time taken for 1 epoch 576.3027451038361 sec\n",
      "\n",
      "Epoch 1 Loss 0.0328\n",
      "Time taken for 1 epoch 594.9484317302704 sec\n",
      "\n",
      "Epoch 1 Loss 0.0332\n",
      "Time taken for 1 epoch 610.3084013462067 sec\n",
      "\n",
      "Epoch 1 Loss 0.0339\n",
      "Time taken for 1 epoch 625.0653877258301 sec\n",
      "\n",
      "Epoch 1 Loss 0.0350\n",
      "Time taken for 1 epoch 639.9183969497681 sec\n",
      "\n",
      "Epoch 1 Loss 0.0362\n",
      "Time taken for 1 epoch 653.0975377559662 sec\n",
      "\n",
      "Epoch 1 Loss 0.0372\n",
      "Time taken for 1 epoch 666.2050507068634 sec\n",
      "\n",
      "Epoch 1 Loss 0.0381\n",
      "Time taken for 1 epoch 678.7871670722961 sec\n",
      "\n",
      "Epoch 1 Loss 0.0389\n",
      "Time taken for 1 epoch 690.22216796875 sec\n",
      "\n",
      "Epoch 1 Loss 0.0397\n",
      "Time taken for 1 epoch 705.1272506713867 sec\n",
      "\n",
      "Epoch 1 Loss 0.0407\n",
      "Time taken for 1 epoch 719.630250453949 sec\n",
      "\n",
      "Epoch 1 Loss 0.0420\n",
      "Time taken for 1 epoch 733.3040902614594 sec\n",
      "\n",
      "Epoch 1 Loss 0.0430\n",
      "Time taken for 1 epoch 748.3180892467499 sec\n",
      "\n",
      "Epoch 1 Loss 0.0439\n",
      "Time taken for 1 epoch 766.9272081851959 sec\n",
      "\n",
      "Epoch 1 Loss 0.0449\n",
      "Time taken for 1 epoch 782.3773453235626 sec\n",
      "\n",
      "Epoch 1 Loss 0.0456\n",
      "Time taken for 1 epoch 795.4305374622345 sec\n",
      "\n",
      "Epoch 1 Loss 0.0463\n",
      "Time taken for 1 epoch 809.6129233837128 sec\n",
      "\n",
      "Epoch 1 Loss 0.0470\n",
      "Time taken for 1 epoch 846.6650207042694 sec\n",
      "\n",
      "Epoch 1 Loss 0.0480\n",
      "Time taken for 1 epoch 862.394534111023 sec\n",
      "\n",
      "Epoch 1 Loss 0.0489\n",
      "Time taken for 1 epoch 873.7085337638855 sec\n",
      "\n",
      "Epoch 1 Loss 0.0496\n",
      "Time taken for 1 epoch 885.8895993232727 sec\n",
      "\n",
      "Epoch 1 Loss 0.0505\n",
      "Time taken for 1 epoch 905.2206227779388 sec\n",
      "\n",
      "Epoch 1 Loss 0.0514\n",
      "Time taken for 1 epoch 919.3087966442108 sec\n",
      "\n",
      "Epoch 1 Loss 0.0521\n",
      "Time taken for 1 epoch 934.008796453476 sec\n",
      "\n",
      "Epoch 1 Loss 0.0527\n",
      "Time taken for 1 epoch 969.9691452980042 sec\n",
      "\n",
      "Epoch 1 Loss 0.0535\n",
      "Time taken for 1 epoch 985.4752349853516 sec\n",
      "\n",
      "Epoch 1 Loss 0.0549\n",
      "Time taken for 1 epoch 1004.5437500476837 sec\n",
      "\n",
      "Epoch 1 Loss 0.0559\n",
      "Time taken for 1 epoch 1023.3620464801788 sec\n",
      "\n",
      "Epoch 1 Loss 0.0566\n",
      "Time taken for 1 epoch 1063.8447222709656 sec\n",
      "\n",
      "Epoch 1 Loss 0.0572\n",
      "Time taken for 1 epoch 1078.6198165416718 sec\n",
      "\n",
      "Epoch 1 Loss 0.0580\n",
      "Time taken for 1 epoch 1094.6278505325317 sec\n",
      "\n",
      "Epoch 1 Loss 0.0589\n",
      "Time taken for 1 epoch 1109.0468475818634 sec\n",
      "\n",
      "Epoch 1 Loss 0.0596\n",
      "Time taken for 1 epoch 1127.0218758583069 sec\n",
      "\n",
      "Epoch 1 Loss 0.0601\n",
      "Time taken for 1 epoch 1139.90696310997 sec\n",
      "\n",
      "Epoch 1 Loss 0.0606\n",
      "Time taken for 1 epoch 1158.0135550498962 sec\n",
      "\n",
      "Epoch 1 Loss 0.0619\n",
      "Time taken for 1 epoch 1174.1946187019348 sec\n",
      "\n",
      "Epoch 1 Loss 0.0625\n",
      "Time taken for 1 epoch 1189.8207080364227 sec\n",
      "\n",
      "Epoch 1 Loss 0.0631\n",
      "Time taken for 1 epoch 1206.3094985485077 sec\n",
      "\n",
      "Epoch 1 Loss 0.0636\n",
      "Time taken for 1 epoch 1221.843105316162 sec\n",
      "\n",
      "Epoch 1 Loss 0.0641\n",
      "Time taken for 1 epoch 1236.9211361408234 sec\n",
      "\n",
      "Epoch 1 Loss 0.0647\n",
      "Time taken for 1 epoch 1249.1021382808685 sec\n",
      "\n",
      "Epoch 1 Loss 0.0657\n",
      "Time taken for 1 epoch 1261.855137348175 sec\n",
      "\n",
      "Epoch 1 Loss 0.0670\n",
      "Time taken for 1 epoch 1276.57013630867 sec\n",
      "\n",
      "Epoch 1 Loss 0.0675\n",
      "Time taken for 1 epoch 1292.8637011051178 sec\n",
      "\n",
      "Epoch 1 Loss 0.0685\n",
      "Time taken for 1 epoch 1308.849289894104 sec\n",
      "\n",
      "Epoch 1 Loss 0.0692\n",
      "Time taken for 1 epoch 1322.243088722229 sec\n",
      "\n",
      "Epoch 1 Loss 0.0703\n",
      "Time taken for 1 epoch 1337.092600107193 sec\n",
      "\n",
      "Epoch 1 Loss 0.0713\n",
      "Time taken for 1 epoch 1355.3507928848267 sec\n",
      "\n",
      "Epoch 1 Loss 0.0725\n",
      "Time taken for 1 epoch 1372.8373892307281 sec\n",
      "\n",
      "Epoch 1 Loss 0.0730\n",
      "Time taken for 1 epoch 1385.9988858699799 sec\n",
      "\n",
      "Epoch 1 Loss 0.0739\n",
      "Time taken for 1 epoch 1398.1194021701813 sec\n",
      "\n",
      "Epoch 1 Loss 0.0744\n",
      "Time taken for 1 epoch 1413.3824005126953 sec\n",
      "\n",
      "Epoch 1 Loss 0.0751\n",
      "Time taken for 1 epoch 1428.0614018440247 sec\n",
      "\n",
      "Epoch 1 Loss 0.0758\n",
      "Time taken for 1 epoch 1442.962448835373 sec\n",
      "\n",
      "Epoch 1 Loss 0.0764\n",
      "Time taken for 1 epoch 1456.3087363243103 sec\n",
      "\n",
      "Epoch 1 Loss 0.0775\n",
      "Time taken for 1 epoch 1482.8792552947998 sec\n",
      "\n",
      "Epoch 1 Loss 0.0786\n",
      "Time taken for 1 epoch 1501.2753126621246 sec\n",
      "\n",
      "Epoch 1 Loss 0.0795\n",
      "Time taken for 1 epoch 1517.3773114681244 sec\n",
      "\n",
      "Epoch 1 Loss 0.0802\n",
      "Time taken for 1 epoch 1532.3563351631165 sec\n",
      "\n",
      "Epoch 1 Loss 0.0812\n",
      "Time taken for 1 epoch 1549.4382359981537 sec\n",
      "\n",
      "Epoch 1 Loss 0.0818\n",
      "Time taken for 1 epoch 1564.1358649730682 sec\n",
      "\n",
      "Epoch 1 Loss 0.0827\n",
      "Time taken for 1 epoch 1577.7521815299988 sec\n",
      "\n",
      "Epoch 1 Loss 0.0842\n",
      "Time taken for 1 epoch 1595.5971846580505 sec\n",
      "\n",
      "Epoch 1 Loss 0.0853\n",
      "Time taken for 1 epoch 1610.0890061855316 sec\n",
      "\n",
      "Epoch 1 Loss 0.0864\n",
      "Time taken for 1 epoch 1631.9318747520447 sec\n",
      "\n",
      "Epoch 1 Loss 0.0872\n",
      "Time taken for 1 epoch 1646.7548744678497 sec\n",
      "\n",
      "Epoch 1 Batch 100 Loss 2.934760\n",
      "Epoch 1 Loss 0.0880\n",
      "Time taken for 1 epoch 1662.4203839302063 sec\n",
      "\n",
      "Epoch 1 Loss 0.0889\n",
      "Time taken for 1 epoch 1678.7093851566315 sec\n",
      "\n",
      "Epoch 1 Loss 0.0898\n",
      "Time taken for 1 epoch 1722.068617105484 sec\n",
      "\n",
      "Epoch 1 Loss 0.0908\n",
      "Time taken for 1 epoch 1735.9436173439026 sec\n",
      "\n",
      "Epoch 1 Loss 0.0917\n",
      "Time taken for 1 epoch 1752.4216220378876 sec\n",
      "\n",
      "Epoch 1 Loss 0.0925\n",
      "Time taken for 1 epoch 1771.0041289329529 sec\n",
      "\n",
      "Epoch 1 Loss 0.0934\n",
      "Time taken for 1 epoch 1787.4066681861877 sec\n",
      "\n",
      "Epoch 1 Loss 0.0947\n",
      "Time taken for 1 epoch 1808.9329402446747 sec\n",
      "\n",
      "Epoch 1 Loss 0.0952\n",
      "Time taken for 1 epoch 1821.820966243744 sec\n",
      "\n",
      "Epoch 1 Loss 0.0962\n",
      "Time taken for 1 epoch 1836.5461838245392 sec\n",
      "\n",
      "Epoch 1 Loss 0.0968\n",
      "Time taken for 1 epoch 1850.3388316631317 sec\n",
      "\n",
      "Epoch 1 Loss 0.0975\n",
      "Time taken for 1 epoch 1861.9113459587097 sec\n",
      "\n",
      "Epoch 1 Loss 0.0984\n",
      "Time taken for 1 epoch 1877.8831899166107 sec\n",
      "\n",
      "Epoch 1 Loss 0.0991\n",
      "Time taken for 1 epoch 1893.8235955238342 sec\n",
      "\n",
      "Epoch 1 Loss 0.0998\n",
      "Time taken for 1 epoch 1909.1311104297638 sec\n",
      "\n",
      "Epoch 1 Loss 0.1005\n",
      "Time taken for 1 epoch 1923.6991353034973 sec\n",
      "\n",
      "Epoch 1 Loss 0.1011\n",
      "Time taken for 1 epoch 1935.26313662529 sec\n",
      "\n",
      "Epoch 1 Loss 0.1019\n",
      "Time taken for 1 epoch 1950.1623203754425 sec\n",
      "\n",
      "Epoch 1 Loss 0.1024\n",
      "Time taken for 1 epoch 1968.9734482765198 sec\n",
      "\n",
      "Epoch 1 Loss 0.1030\n",
      "Time taken for 1 epoch 1989.8598806858063 sec\n",
      "\n",
      "Epoch 1 Loss 0.1037\n",
      "Time taken for 1 epoch 2010.3877022266388 sec\n",
      "\n",
      "Epoch 1 Loss 0.1044\n",
      "Time taken for 1 epoch 2025.8173353672028 sec\n",
      "\n",
      "Epoch 1 Loss 0.1051\n",
      "Time taken for 1 epoch 2040.9083359241486 sec\n",
      "\n",
      "Epoch 1 Loss 0.1058\n",
      "Time taken for 1 epoch 2055.9753358364105 sec\n",
      "\n",
      "Epoch 1 Loss 0.1064\n",
      "Time taken for 1 epoch 2069.294335126877 sec\n",
      "\n",
      "Epoch 1 Loss 0.1071\n",
      "Time taken for 1 epoch 2083.0173375606537 sec\n",
      "\n",
      "Epoch 1 Loss 0.1081\n",
      "Time taken for 1 epoch 2097.6483311653137 sec\n",
      "\n",
      "Epoch 1 Loss 0.1092\n",
      "Time taken for 1 epoch 2112.610594511032 sec\n",
      "\n",
      "Epoch 1 Loss 0.1099\n",
      "Time taken for 1 epoch 2127.2616004943848 sec\n",
      "\n",
      "Epoch 1 Loss 0.1105\n",
      "Time taken for 1 epoch 2142.6994540691376 sec\n",
      "\n",
      "Epoch 1 Loss 0.1111\n",
      "Time taken for 1 epoch 2156.617083787918 sec\n",
      "\n",
      "Epoch 1 Loss 0.1118\n",
      "Time taken for 1 epoch 2173.488088130951 sec\n",
      "\n",
      "Epoch 1 Loss 0.1124\n",
      "Time taken for 1 epoch 2191.247087955475 sec\n",
      "\n",
      "Epoch 1 Loss 0.1135\n",
      "Time taken for 1 epoch 2206.0505785942078 sec\n",
      "\n",
      "Epoch 1 Loss 0.1144\n",
      "Time taken for 1 epoch 2221.400580406189 sec\n",
      "\n",
      "Epoch 1 Loss 0.1152\n",
      "Time taken for 1 epoch 2236.3751034736633 sec\n",
      "\n",
      "Epoch 1 Loss 0.1157\n",
      "Time taken for 1 epoch 2249.9321010112762 sec\n",
      "\n",
      "Epoch 1 Loss 0.1164\n",
      "Time taken for 1 epoch 2263.2011013031006 sec\n",
      "\n",
      "Epoch 1 Loss 0.1171\n",
      "Time taken for 1 epoch 2275.2911014556885 sec\n",
      "\n",
      "Epoch 1 Loss 0.1179\n",
      "Time taken for 1 epoch 2289.1321017742157 sec\n",
      "\n",
      "Epoch 1 Loss 0.1188\n",
      "Time taken for 1 epoch 2307.2791035175323 sec\n",
      "\n",
      "Epoch 1 Loss 0.1195\n",
      "Time taken for 1 epoch 2321.6301238536835 sec\n",
      "\n",
      "Epoch 1 Loss 0.1205\n",
      "Time taken for 1 epoch 2335.627649307251 sec\n",
      "\n",
      "Epoch 1 Loss 0.1211\n",
      "Time taken for 1 epoch 2346.4526472091675 sec\n",
      "\n",
      "Epoch 1 Loss 0.1221\n",
      "Time taken for 1 epoch 2361.858647584915 sec\n",
      "\n",
      "Epoch 1 Loss 0.1225\n",
      "Time taken for 1 epoch 2378.4010846614838 sec\n",
      "\n",
      "Epoch 1 Loss 0.1234\n",
      "Time taken for 1 epoch 2389.1488933563232 sec\n",
      "\n",
      "Epoch 1 Loss 0.1242\n",
      "Time taken for 1 epoch 2403.806062936783 sec\n",
      "\n",
      "Epoch 1 Loss 0.1250\n",
      "Time taken for 1 epoch 2415.9495992660522 sec\n",
      "\n",
      "Epoch 1 Loss 0.1260\n",
      "Time taken for 1 epoch 2432.6228127479553 sec\n",
      "\n",
      "Epoch 1 Loss 0.1267\n",
      "Time taken for 1 epoch 2445.6457891464233 sec\n",
      "\n",
      "Epoch 1 Loss 0.1274\n",
      "Time taken for 1 epoch 2459.542192220688 sec\n",
      "\n",
      "Epoch 1 Loss 0.1283\n",
      "Time taken for 1 epoch 2473.3621923923492 sec\n",
      "\n",
      "Epoch 1 Loss 0.1292\n",
      "Time taken for 1 epoch 2490.0276029109955 sec\n",
      "\n",
      "Epoch 1 Loss 0.1302\n",
      "Time taken for 1 epoch 2503.2506606578827 sec\n",
      "\n",
      "Epoch 1 Loss 0.1309\n",
      "Time taken for 1 epoch 2517.516659259796 sec\n",
      "\n",
      "Epoch 1 Loss 0.1316\n",
      "Time taken for 1 epoch 2535.140966653824 sec\n",
      "\n",
      "Epoch 1 Loss 0.1325\n",
      "Time taken for 1 epoch 2549.3040285110474 sec\n",
      "\n",
      "Epoch 1 Loss 0.1333\n",
      "Time taken for 1 epoch 2562.832028388977 sec\n",
      "\n",
      "Epoch 1 Loss 0.1338\n",
      "Time taken for 1 epoch 2586.836315393448 sec\n",
      "\n",
      "Epoch 1 Loss 0.1349\n",
      "Time taken for 1 epoch 2604.543314933777 sec\n",
      "\n",
      "Epoch 1 Loss 0.1357\n",
      "Time taken for 1 epoch 2621.3143577575684 sec\n",
      "\n",
      "Epoch 1 Loss 0.1366\n",
      "Time taken for 1 epoch 2636.7083575725555 sec\n",
      "\n",
      "Epoch 1 Loss 0.1374\n",
      "Time taken for 1 epoch 2649.4763576984406 sec\n",
      "\n",
      "Epoch 1 Loss 0.1385\n",
      "Time taken for 1 epoch 2661.6323573589325 sec\n",
      "\n",
      "Epoch 1 Loss 0.1397\n",
      "Time taken for 1 epoch 2678.126360177994 sec\n",
      "\n",
      "Epoch 1 Loss 0.1404\n",
      "Time taken for 1 epoch 2690.432357311249 sec\n",
      "\n",
      "Epoch 1 Loss 0.1411\n",
      "Time taken for 1 epoch 2706.1896290779114 sec\n",
      "\n",
      "Epoch 1 Loss 0.1420\n",
      "Time taken for 1 epoch 2720.232142686844 sec\n",
      "\n",
      "Epoch 1 Loss 0.1430\n",
      "Time taken for 1 epoch 2736.9341700077057 sec\n",
      "\n",
      "Epoch 1 Loss 0.1442\n",
      "Time taken for 1 epoch 2752.119170188904 sec\n",
      "\n",
      "Epoch 1 Loss 0.1455\n",
      "Time taken for 1 epoch 2767.1375720500946 sec\n",
      "\n",
      "Epoch 1 Loss 0.1461\n",
      "Time taken for 1 epoch 2780.5155601501465 sec\n",
      "\n",
      "Epoch 1 Loss 0.1469\n",
      "Time taken for 1 epoch 2793.4362642765045 sec\n",
      "\n",
      "Epoch 1 Loss 0.1475\n",
      "Time taken for 1 epoch 2808.091262817383 sec\n",
      "\n",
      "Epoch 1 Loss 0.1488\n",
      "Time taken for 1 epoch 2826.3175094127655 sec\n",
      "\n",
      "Epoch 1 Loss 0.1495\n",
      "Time taken for 1 epoch 2840.2341089248657 sec\n",
      "\n",
      "Epoch 1 Loss 0.1507\n",
      "Time taken for 1 epoch 2859.3114290237427 sec\n",
      "\n",
      "Epoch 1 Loss 0.1513\n",
      "Time taken for 1 epoch 2870.6484277248383 sec\n",
      "\n",
      "Epoch 1 Loss 0.1523\n",
      "Time taken for 1 epoch 2888.0204269886017 sec\n",
      "\n",
      "Epoch 1 Loss 0.1533\n",
      "Time taken for 1 epoch 2902.892554283142 sec\n",
      "\n",
      "Epoch 1 Loss 0.1539\n",
      "Time taken for 1 epoch 2916.434552669525 sec\n",
      "\n",
      "Epoch 1 Loss 0.1548\n",
      "Time taken for 1 epoch 2932.675740003586 sec\n",
      "\n",
      "Epoch 1 Loss 0.1554\n",
      "Time taken for 1 epoch 2947.1413118839264 sec\n",
      "\n",
      "Epoch 1 Loss 0.1564\n",
      "Time taken for 1 epoch 2961.4126801490784 sec\n",
      "\n",
      "Epoch 1 Loss 0.1576\n",
      "Time taken for 1 epoch 2975.25332736969 sec\n",
      "\n",
      "Epoch 1 Loss 0.1582\n",
      "Time taken for 1 epoch 2990.449330806732 sec\n",
      "\n",
      "Epoch 1 Loss 0.1590\n",
      "Time taken for 1 epoch 3006.6193664073944 sec\n",
      "\n",
      "Epoch 1 Loss 0.1599\n",
      "Time taken for 1 epoch 3019.904366493225 sec\n",
      "\n",
      "Epoch 1 Loss 0.1608\n",
      "Time taken for 1 epoch 3036.9021475315094 sec\n",
      "\n",
      "Epoch 1 Loss 0.1618\n",
      "Time taken for 1 epoch 3052.5731480121613 sec\n",
      "\n",
      "Epoch 1 Loss 0.1627\n",
      "Time taken for 1 epoch 3067.374977350235 sec\n",
      "\n",
      "Epoch 1 Loss 0.1632\n",
      "Time taken for 1 epoch 3080.704857826233 sec\n",
      "\n",
      "Epoch 1 Loss 0.1641\n",
      "Time taken for 1 epoch 3095.6942999362946 sec\n",
      "\n",
      "Epoch 1 Loss 0.1649\n",
      "Time taken for 1 epoch 3109.8603003025055 sec\n",
      "\n",
      "Epoch 1 Loss 0.1656\n",
      "Time taken for 1 epoch 3124.847552061081 sec\n",
      "\n",
      "Epoch 1 Loss 0.1663\n",
      "Time taken for 1 epoch 3141.124707698822 sec\n",
      "\n",
      "Epoch 1 Loss 0.1668\n",
      "Time taken for 1 epoch 3155.787707090378 sec\n",
      "\n",
      "Epoch 1 Loss 0.1677\n",
      "Time taken for 1 epoch 3171.369732618332 sec\n",
      "\n",
      "Epoch 1 Loss 0.1683\n",
      "Time taken for 1 epoch 3186.9592916965485 sec\n",
      "\n",
      "Epoch 1 Batch 200 Loss 4.548231\n",
      "Epoch 1 Loss 0.1695\n",
      "Time taken for 1 epoch 3205.7773554325104 sec\n",
      "\n",
      "Epoch 1 Loss 0.1704\n",
      "Time taken for 1 epoch 3222.086538553238 sec\n",
      "\n",
      "Epoch 1 Loss 0.1713\n",
      "Time taken for 1 epoch 3237.2105383872986 sec\n",
      "\n",
      "Epoch 1 Loss 0.1726\n",
      "Time taken for 1 epoch 3258.3095428943634 sec\n",
      "\n",
      "Epoch 1 Loss 0.1735\n",
      "Time taken for 1 epoch 3274.756204366684 sec\n",
      "\n",
      "Epoch 1 Loss 0.1746\n",
      "Time taken for 1 epoch 3314.7807264328003 sec\n",
      "\n",
      "Epoch 1 Loss 0.1756\n",
      "Time taken for 1 epoch 3331.9287264347076 sec\n",
      "\n",
      "Epoch 1 Loss 0.1770\n",
      "Time taken for 1 epoch 3346.563423395157 sec\n",
      "\n",
      "Epoch 1 Loss 0.1774\n",
      "Time taken for 1 epoch 3361.71101975441 sec\n",
      "\n",
      "Epoch 1 Loss 0.1784\n",
      "Time taken for 1 epoch 3383.214045524597 sec\n",
      "\n",
      "Epoch 1 Loss 0.1794\n",
      "Time taken for 1 epoch 3398.671593427658 sec\n",
      "\n",
      "Epoch 1 Loss 0.1806\n",
      "Time taken for 1 epoch 3412.3051064014435 sec\n",
      "\n",
      "Epoch 1 Loss 0.1817\n",
      "Time taken for 1 epoch 3429.2798595428467 sec\n",
      "\n",
      "Epoch 1 Loss 0.1825\n",
      "Time taken for 1 epoch 3442.880859375 sec\n",
      "\n",
      "Epoch 1 Loss 0.1830\n",
      "Time taken for 1 epoch 3457.796225309372 sec\n",
      "\n",
      "Epoch 1 Loss 0.1838\n",
      "Time taken for 1 epoch 3471.436321735382 sec\n",
      "\n",
      "Epoch 1 Loss 0.1845\n",
      "Time taken for 1 epoch 3486.280846595764 sec\n",
      "\n",
      "Epoch 1 Loss 0.1856\n",
      "Time taken for 1 epoch 3512.227777004242 sec\n",
      "\n",
      "Epoch 1 Loss 0.1866\n",
      "Time taken for 1 epoch 3532.38894367218 sec\n",
      "\n",
      "Epoch 1 Loss 0.1871\n",
      "Time taken for 1 epoch 3548.4585378170013 sec\n",
      "\n",
      "Epoch 1 Loss 0.1878\n",
      "Time taken for 1 epoch 3571.7301862239838 sec\n",
      "\n",
      "Epoch 1 Loss 0.1884\n",
      "Time taken for 1 epoch 3585.1599712371826 sec\n",
      "\n",
      "Epoch 1 Loss 0.1890\n",
      "Time taken for 1 epoch 3599.3438925743103 sec\n",
      "\n",
      "Epoch 1 Loss 0.1901\n",
      "Time taken for 1 epoch 3616.8945372104645 sec\n",
      "\n",
      "Epoch 1 Loss 0.1906\n",
      "Time taken for 1 epoch 3629.009537220001 sec\n",
      "\n",
      "Epoch 1 Loss 0.1919\n",
      "Time taken for 1 epoch 3648.8799793720245 sec\n",
      "\n",
      "Epoch 1 Loss 0.1931\n",
      "Time taken for 1 epoch 3667.22443151474 sec\n",
      "\n",
      "Epoch 1 Loss 0.1942\n",
      "Time taken for 1 epoch 3685.5841267108917 sec\n",
      "\n",
      "Epoch 1 Loss 0.1949\n",
      "Time taken for 1 epoch 3697.724126815796 sec\n",
      "\n",
      "Epoch 1 Loss 0.1960\n",
      "Time taken for 1 epoch 3713.5748846530914 sec\n",
      "\n",
      "Epoch 1 Loss 0.1971\n",
      "Time taken for 1 epoch 3731.142184495926 sec\n",
      "\n",
      "Epoch 1 Loss 0.1980\n",
      "Time taken for 1 epoch 3744.8547949790955 sec\n",
      "\n",
      "Epoch 1 Loss 0.1987\n",
      "Time taken for 1 epoch 3761.6807940006256 sec\n",
      "\n",
      "Epoch 1 Loss 0.1995\n",
      "Time taken for 1 epoch 3776.6997950077057 sec\n",
      "\n",
      "Epoch 1 Loss 0.2001\n",
      "Time taken for 1 epoch 3790.9727959632874 sec\n",
      "\n",
      "Epoch 1 Loss 0.2010\n",
      "Time taken for 1 epoch 3808.273553609848 sec\n",
      "\n",
      "Epoch 1 Loss 0.2017\n",
      "Time taken for 1 epoch 3822.5658938884735 sec\n",
      "\n",
      "Epoch 1 Loss 0.2026\n",
      "Time taken for 1 epoch 3837.0898966789246 sec\n",
      "\n",
      "Epoch 1 Loss 0.2039\n",
      "Time taken for 1 epoch 3852.6998937129974 sec\n",
      "\n",
      "Epoch 1 Loss 0.2048\n",
      "Time taken for 1 epoch 3868.790239572525 sec\n",
      "\n",
      "Epoch 1 Loss 0.2052\n",
      "Time taken for 1 epoch 3881.341238260269 sec\n",
      "\n",
      "Epoch 1 Loss 0.2058\n",
      "Time taken for 1 epoch 3893.6973481178284 sec\n",
      "\n",
      "Epoch 1 Loss 0.2066\n",
      "Time taken for 1 epoch 3910.4013476371765 sec\n",
      "\n",
      "Epoch 1 Loss 0.2073\n",
      "Time taken for 1 epoch 3930.7523341178894 sec\n",
      "\n",
      "Epoch 1 Loss 0.2082\n",
      "Time taken for 1 epoch 3946.3813350200653 sec\n",
      "\n",
      "Epoch 1 Loss 0.2090\n",
      "Time taken for 1 epoch 3960.1843345165253 sec\n",
      "\n",
      "Epoch 1 Loss 0.2096\n",
      "Time taken for 1 epoch 3975.893357515335 sec\n",
      "\n",
      "Epoch 1 Loss 0.2103\n",
      "Time taken for 1 epoch 3987.6703572273254 sec\n",
      "\n",
      "Epoch 1 Loss 0.2109\n",
      "Time taken for 1 epoch 4000.351051568985 sec\n",
      "\n",
      "Epoch 1 Loss 0.2118\n",
      "Time taken for 1 epoch 4017.5271456241608 sec\n",
      "\n",
      "Epoch 1 Loss 0.2124\n",
      "Time taken for 1 epoch 4032.6461458206177 sec\n",
      "\n",
      "Epoch 1 Loss 0.2135\n",
      "Time taken for 1 epoch 4049.813731431961 sec\n",
      "\n",
      "Epoch 1 Loss 0.2147\n",
      "Time taken for 1 epoch 4066.9080727100372 sec\n",
      "\n",
      "Epoch 1 Loss 0.2159\n",
      "Time taken for 1 epoch 4085.0704140663147 sec\n",
      "\n",
      "Epoch 1 Loss 0.2170\n",
      "Time taken for 1 epoch 4099.947332620621 sec\n",
      "\n",
      "Epoch 1 Loss 0.2177\n",
      "Time taken for 1 epoch 4114.261333703995 sec\n",
      "\n",
      "Epoch 1 Loss 0.2183\n",
      "Time taken for 1 epoch 4130.037905931473 sec\n",
      "\n",
      "Epoch 1 Loss 0.2193\n",
      "Time taken for 1 epoch 4147.4693768024445 sec\n",
      "\n",
      "Epoch 1 Loss 0.2199\n",
      "Time taken for 1 epoch 4160.267377853394 sec\n",
      "\n",
      "Epoch 1 Loss 0.2209\n",
      "Time taken for 1 epoch 4177.474215507507 sec\n",
      "\n",
      "Epoch 1 Loss 0.2219\n",
      "Time taken for 1 epoch 4196.824820518494 sec\n",
      "\n",
      "Epoch 1 Loss 0.2225\n",
      "Time taken for 1 epoch 4212.6100697517395 sec\n",
      "\n",
      "Epoch 1 Loss 0.2234\n",
      "Time taken for 1 epoch 4229.758665323257 sec\n",
      "\n",
      "Epoch 1 Loss 0.2241\n",
      "Time taken for 1 epoch 4242.355306148529 sec\n",
      "\n",
      "Epoch 1 Loss 0.2248\n",
      "Time taken for 1 epoch 4260.962585449219 sec\n",
      "\n",
      "Epoch 1 Loss 0.2255\n",
      "Time taken for 1 epoch 4276.25110077858 sec\n",
      "\n",
      "Epoch 1 Loss 0.2266\n",
      "Time taken for 1 epoch 4293.852615356445 sec\n",
      "\n",
      "Epoch 1 Loss 0.2276\n",
      "Time taken for 1 epoch 4316.572409629822 sec\n",
      "\n",
      "Epoch 1 Loss 0.2280\n",
      "Time taken for 1 epoch 4330.328410387039 sec\n",
      "\n",
      "Epoch 1 Loss 0.2291\n",
      "Time taken for 1 epoch 4347.25954914093 sec\n",
      "\n",
      "Epoch 1 Loss 0.2302\n",
      "Time taken for 1 epoch 4365.798548936844 sec\n",
      "\n",
      "Epoch 1 Loss 0.2311\n",
      "Time taken for 1 epoch 4380.557349681854 sec\n",
      "\n",
      "Epoch 1 Loss 0.2323\n",
      "Time taken for 1 epoch 4396.934349298477 sec\n",
      "\n",
      "Epoch 1 Loss 0.2334\n",
      "Time taken for 1 epoch 4411.692350387573 sec\n",
      "\n",
      "Epoch 1 Loss 0.2342\n",
      "Time taken for 1 epoch 4424.874093770981 sec\n",
      "\n",
      "Epoch 1 Loss 0.2348\n",
      "Time taken for 1 epoch 4438.089093923569 sec\n",
      "\n",
      "Epoch 1 Loss 0.2356\n",
      "Time taken for 1 epoch 4450.734074354172 sec\n",
      "\n",
      "Epoch 1 Loss 0.2361\n",
      "Time taken for 1 epoch 4466.244075059891 sec\n",
      "\n",
      "Epoch 1 Loss 0.2369\n",
      "Time taken for 1 epoch 4482.000655174255 sec\n",
      "\n",
      "Epoch 1 Loss 0.2378\n",
      "Time taken for 1 epoch 4497.474856376648 sec\n",
      "\n",
      "Epoch 1 Loss 0.2389\n",
      "Time taken for 1 epoch 4512.199694395065 sec\n",
      "\n",
      "Epoch 1 Loss 0.2398\n",
      "Time taken for 1 epoch 4528.998784303665 sec\n",
      "\n",
      "Epoch 1 Loss 0.2407\n",
      "Time taken for 1 epoch 4542.496797084808 sec\n",
      "\n",
      "Epoch 1 Loss 0.2415\n",
      "Time taken for 1 epoch 4557.079797029495 sec\n",
      "\n",
      "Epoch 1 Loss 0.2426\n",
      "Time taken for 1 epoch 4573.867799043655 sec\n",
      "\n",
      "Epoch 1 Loss 0.2436\n",
      "Time taken for 1 epoch 4587.081798315048 sec\n",
      "\n",
      "Epoch 1 Loss 0.2444\n",
      "Time taken for 1 epoch 4603.363070011139 sec\n",
      "\n",
      "Epoch 1 Loss 0.2455\n",
      "Time taken for 1 epoch 4619.519953727722 sec\n",
      "\n",
      "Epoch 1 Loss 0.2465\n",
      "Time taken for 1 epoch 4635.81352186203 sec\n",
      "\n",
      "Epoch 1 Loss 0.2473\n",
      "Time taken for 1 epoch 4648.979522228241 sec\n",
      "\n",
      "Epoch 1 Loss 0.2480\n",
      "Time taken for 1 epoch 4665.931221008301 sec\n",
      "\n",
      "Epoch 1 Loss 0.2485\n",
      "Time taken for 1 epoch 4680.008880853653 sec\n",
      "\n",
      "Epoch 1 Loss 0.2496\n",
      "Time taken for 1 epoch 4694.484722614288 sec\n",
      "\n",
      "Epoch 1 Loss 0.2501\n",
      "Time taken for 1 epoch 4707.486098766327 sec\n",
      "\n",
      "Epoch 1 Loss 0.2510\n",
      "Time taken for 1 epoch 4720.547865629196 sec\n",
      "\n",
      "Epoch 1 Loss 0.2523\n",
      "Time taken for 1 epoch 4736.160923480988 sec\n",
      "\n",
      "Epoch 1 Loss 0.2528\n",
      "Time taken for 1 epoch 4748.829924821854 sec\n",
      "\n",
      "Epoch 1 Loss 0.2535\n",
      "Time taken for 1 epoch 4762.5229234695435 sec\n",
      "\n",
      "Epoch 1 Loss 0.2542\n",
      "Time taken for 1 epoch 4777.330354690552 sec\n",
      "\n",
      "Epoch 1 Loss 0.2552\n",
      "Time taken for 1 epoch 4792.451354980469 sec\n",
      "\n",
      "Epoch 1 Batch 300 Loss 1.830727\n",
      "Epoch 1 Loss 0.2557\n",
      "Time taken for 1 epoch 4806.1303515434265 sec\n",
      "\n",
      "Epoch 1 Loss 0.2567\n",
      "Time taken for 1 epoch 4820.990104675293 sec\n",
      "\n",
      "Epoch 1 Loss 0.2578\n",
      "Time taken for 1 epoch 4835.087105512619 sec\n",
      "\n",
      "Epoch 1 Loss 0.2583\n",
      "Time taken for 1 epoch 4848.049299240112 sec\n",
      "\n",
      "Epoch 1 Loss 0.2594\n",
      "Time taken for 1 epoch 4864.196340799332 sec\n",
      "\n",
      "Epoch 1 Loss 0.2601\n",
      "Time taken for 1 epoch 4879.325348377228 sec\n",
      "\n",
      "Epoch 1 Loss 0.2613\n",
      "Time taken for 1 epoch 4894.412345409393 sec\n",
      "\n",
      "Epoch 1 Loss 0.2621\n",
      "Time taken for 1 epoch 4911.8653473854065 sec\n",
      "\n",
      "Epoch 1 Loss 0.2628\n",
      "Time taken for 1 epoch 4925.914345502853 sec\n",
      "\n",
      "Epoch 1 Loss 0.2635\n",
      "Time taken for 1 epoch 4939.400454998016 sec\n",
      "\n",
      "Epoch 1 Loss 0.2644\n",
      "Time taken for 1 epoch 4950.819454908371 sec\n",
      "\n",
      "Epoch 1 Loss 0.2649\n",
      "Time taken for 1 epoch 4963.42045545578 sec\n",
      "\n",
      "Epoch 1 Loss 0.2657\n",
      "Time taken for 1 epoch 4977.779455900192 sec\n",
      "\n",
      "Epoch 1 Loss 0.2664\n",
      "Time taken for 1 epoch 4992.049886226654 sec\n",
      "\n",
      "Epoch 1 Loss 0.2674\n",
      "Time taken for 1 epoch 5009.373057603836 sec\n",
      "\n",
      "Epoch 1 Loss 0.2683\n",
      "Time taken for 1 epoch 5023.026057243347 sec\n",
      "\n",
      "Epoch 1 Loss 0.2691\n",
      "Time taken for 1 epoch 5038.027057170868 sec\n",
      "\n",
      "Epoch 1 Loss 0.2698\n",
      "Time taken for 1 epoch 5052.3840572834015 sec\n",
      "\n",
      "Epoch 1 Loss 0.2707\n",
      "Time taken for 1 epoch 5066.58605837822 sec\n",
      "\n",
      "Epoch 1 Loss 0.2714\n",
      "Time taken for 1 epoch 5080.4519629478455 sec\n",
      "\n",
      "Epoch 1 Loss 0.2725\n",
      "Time taken for 1 epoch 5095.339967250824 sec\n",
      "\n",
      "Epoch 1 Loss 0.2733\n",
      "Time taken for 1 epoch 5109.808964252472 sec\n",
      "\n",
      "Epoch 1 Loss 0.2747\n",
      "Time taken for 1 epoch 5125.82399725914 sec\n",
      "\n",
      "Epoch 1 Loss 0.2758\n",
      "Time taken for 1 epoch 5141.408691644669 sec\n",
      "\n",
      "Epoch 1 Loss 0.2767\n",
      "Time taken for 1 epoch 5156.574691772461 sec\n",
      "\n",
      "Epoch 1 Loss 0.2780\n",
      "Time taken for 1 epoch 5171.089691400528 sec\n",
      "\n",
      "Epoch 1 Loss 0.2788\n",
      "Time taken for 1 epoch 5183.721691131592 sec\n",
      "\n",
      "Epoch 1 Loss 0.2796\n",
      "Time taken for 1 epoch 5195.3496906757355 sec\n",
      "\n",
      "Epoch 1 Loss 0.2808\n",
      "Time taken for 1 epoch 5217.016476392746 sec\n",
      "\n",
      "Epoch 1 Loss 0.2821\n",
      "Time taken for 1 epoch 5232.079477071762 sec\n",
      "\n",
      "Epoch 1 Loss 0.2826\n",
      "Time taken for 1 epoch 5245.176476955414 sec\n",
      "\n",
      "Epoch 1 Loss 0.2838\n",
      "Time taken for 1 epoch 5260.175476074219 sec\n",
      "\n",
      "Epoch 1 Loss 0.2847\n",
      "Time taken for 1 epoch 5273.543008089066 sec\n",
      "\n",
      "Epoch 1 Loss 0.2852\n",
      "Time taken for 1 epoch 5286.444685459137 sec\n",
      "\n",
      "Epoch 1 Loss 0.2858\n",
      "Time taken for 1 epoch 5299.835360765457 sec\n",
      "\n",
      "Epoch 1 Loss 0.2866\n",
      "Time taken for 1 epoch 5314.39527630806 sec\n",
      "\n",
      "Epoch 1 Loss 0.2874\n",
      "Time taken for 1 epoch 5330.128124713898 sec\n",
      "\n",
      "Epoch 1 Loss 0.2881\n",
      "Time taken for 1 epoch 5342.942605257034 sec\n",
      "\n",
      "Epoch 1 Loss 0.2889\n",
      "Time taken for 1 epoch 5357.887606620789 sec\n",
      "\n",
      "Epoch 1 Loss 0.2899\n",
      "Time taken for 1 epoch 5372.581604957581 sec\n",
      "\n",
      "Epoch 1 Loss 0.2906\n",
      "Time taken for 1 epoch 5385.597607374191 sec\n",
      "\n",
      "Epoch 1 Loss 0.2910\n",
      "Time taken for 1 epoch 5400.512419700623 sec\n",
      "\n",
      "Epoch 1 Loss 0.2924\n",
      "Time taken for 1 epoch 5416.283161878586 sec\n",
      "\n",
      "Epoch 1 Loss 0.2931\n",
      "Time taken for 1 epoch 5430.7941682338715 sec\n",
      "\n",
      "Epoch 1 Loss 0.2941\n",
      "Time taken for 1 epoch 5443.6953229904175 sec\n",
      "\n",
      "Epoch 1 Loss 0.2948\n",
      "Time taken for 1 epoch 5459.541323184967 sec\n",
      "\n",
      "Epoch 1 Loss 0.2955\n",
      "Time taken for 1 epoch 5472.760321140289 sec\n",
      "\n",
      "Epoch 1 Loss 0.2965\n",
      "Time taken for 1 epoch 5489.336922645569 sec\n",
      "\n",
      "Epoch 1 Loss 0.2972\n",
      "Time taken for 1 epoch 5519.268351793289 sec\n",
      "\n",
      "Epoch 1 Loss 0.2982\n",
      "Time taken for 1 epoch 5537.977918624878 sec\n",
      "\n",
      "Epoch 1 Loss 0.2991\n",
      "Time taken for 1 epoch 5552.498624563217 sec\n",
      "\n",
      "Epoch 1 Loss 0.2997\n",
      "Time taken for 1 epoch 5566.466624736786 sec\n",
      "\n",
      "Epoch 1 Loss 0.3008\n",
      "Time taken for 1 epoch 5582.111439704895 sec\n",
      "\n",
      "Epoch 1 Loss 0.3015\n",
      "Time taken for 1 epoch 5595.974328994751 sec\n",
      "\n",
      "Epoch 1 Loss 0.3022\n",
      "Time taken for 1 epoch 5611.657329320908 sec\n",
      "\n",
      "Epoch 1 Loss 0.3031\n",
      "Time taken for 1 epoch 5629.407912492752 sec\n",
      "\n",
      "Epoch 1 Loss 0.3040\n",
      "Time taken for 1 epoch 5642.776893615723 sec\n",
      "\n",
      "Epoch 1 Loss 0.3049\n",
      "Time taken for 1 epoch 5658.477282524109 sec\n",
      "\n",
      "Epoch 1 Loss 0.3053\n",
      "Time taken for 1 epoch 5669.731281518936 sec\n",
      "\n",
      "Epoch 1 Loss 0.3066\n",
      "Time taken for 1 epoch 5688.17228102684 sec\n",
      "\n",
      "Epoch 1 Loss 0.3078\n",
      "Time taken for 1 epoch 5708.76295208931 sec\n",
      "\n",
      "Epoch 1 Loss 0.3088\n",
      "Time taken for 1 epoch 5722.933733463287 sec\n",
      "\n",
      "Epoch 1 Loss 0.3097\n",
      "Time taken for 1 epoch 5737.969742774963 sec\n",
      "\n",
      "Epoch 1 Loss 0.3104\n",
      "Time taken for 1 epoch 5753.448742866516 sec\n",
      "\n",
      "Epoch 1 Loss 0.3113\n",
      "Time taken for 1 epoch 5766.907851219177 sec\n",
      "\n",
      "Epoch 1 Loss 0.3118\n",
      "Time taken for 1 epoch 5779.802539587021 sec\n",
      "\n",
      "Epoch 1 Loss 0.3128\n",
      "Time taken for 1 epoch 5793.477539539337 sec\n",
      "\n",
      "Epoch 1 Loss 0.3137\n",
      "Time taken for 1 epoch 5808.807539701462 sec\n",
      "\n",
      "Epoch 1 Loss 0.3148\n",
      "Time taken for 1 epoch 5822.617537736893 sec\n",
      "\n",
      "Epoch 1 Loss 0.3155\n",
      "Time taken for 1 epoch 5839.1875376701355 sec\n",
      "\n",
      "Epoch 1 Loss 0.3164\n",
      "Time taken for 1 epoch 5853.303104400635 sec\n",
      "\n",
      "Epoch 1 Loss 0.3171\n",
      "Time taken for 1 epoch 5868.113104343414 sec\n",
      "\n",
      "Epoch 1 Loss 0.3177\n",
      "Time taken for 1 epoch 5881.763300895691 sec\n",
      "\n",
      "Epoch 1 Loss 0.3184\n",
      "Time taken for 1 epoch 5895.856309175491 sec\n",
      "\n",
      "Epoch 1 Loss 0.3191\n",
      "Time taken for 1 epoch 5910.462327718735 sec\n",
      "\n",
      "Epoch 1 Loss 0.3202\n",
      "Time taken for 1 epoch 5925.123328208923 sec\n",
      "\n",
      "Epoch 1 Loss 0.3212\n",
      "Time taken for 1 epoch 5940.332247257233 sec\n",
      "\n",
      "Epoch 1 Loss 0.3219\n",
      "Time taken for 1 epoch 5957.092246055603 sec\n",
      "\n",
      "Epoch 1 Loss 0.3226\n",
      "Time taken for 1 epoch 5970.470683813095 sec\n",
      "\n",
      "Epoch 1 Loss 0.3236\n",
      "Time taken for 1 epoch 5988.014684677124 sec\n",
      "\n",
      "Epoch 1 Loss 0.3241\n",
      "Time taken for 1 epoch 6002.724447011948 sec\n",
      "\n",
      "Epoch 1 Loss 0.3250\n",
      "Time taken for 1 epoch 6017.842932939529 sec\n",
      "\n",
      "Epoch 1 Loss 0.3259\n",
      "Time taken for 1 epoch 6033.706931114197 sec\n",
      "\n",
      "Epoch 1 Loss 0.3266\n",
      "Time taken for 1 epoch 6047.680313825607 sec\n",
      "\n",
      "Epoch 1 Loss 0.3277\n",
      "Time taken for 1 epoch 6063.702795743942 sec\n",
      "\n",
      "Epoch 1 Loss 0.3289\n",
      "Time taken for 1 epoch 6080.055543899536 sec\n",
      "\n",
      "Epoch 1 Loss 0.3304\n",
      "Time taken for 1 epoch 6096.601543426514 sec\n",
      "\n",
      "Epoch 1 Loss 0.3310\n",
      "Time taken for 1 epoch 6110.126001358032 sec\n",
      "\n",
      "Epoch 1 Loss 0.3317\n",
      "Time taken for 1 epoch 6124.197035551071 sec\n",
      "\n",
      "Epoch 1 Loss 0.3324\n",
      "Time taken for 1 epoch 6140.49801492691 sec\n",
      "\n",
      "Epoch 1 Loss 0.3331\n",
      "Time taken for 1 epoch 6155.8020277023315 sec\n",
      "\n",
      "Epoch 1 Loss 0.3338\n",
      "Time taken for 1 epoch 6170.1600296497345 sec\n",
      "\n",
      "Epoch 1 Loss 0.3347\n",
      "Time taken for 1 epoch 6205.032767057419 sec\n",
      "\n",
      "Epoch 1 Loss 0.3355\n",
      "Time taken for 1 epoch 6217.527766942978 sec\n",
      "\n",
      "Epoch 1 Loss 0.3361\n",
      "Time taken for 1 epoch 6228.679767131805 sec\n",
      "\n",
      "Epoch 1 Loss 0.3369\n",
      "Time taken for 1 epoch 6246.995766878128 sec\n",
      "\n",
      "Epoch 1 Loss 0.3377\n",
      "Time taken for 1 epoch 6263.9073832035065 sec\n",
      "\n",
      "Epoch 1 Loss 0.3386\n",
      "Time taken for 1 epoch 6282.470005989075 sec\n",
      "\n",
      "Epoch 1 Loss 0.3395\n",
      "Time taken for 1 epoch 6296.722005367279 sec\n",
      "\n",
      "Epoch 1 Loss 0.3403\n",
      "Time taken for 1 epoch 6311.886528015137 sec\n",
      "\n",
      "Epoch 1 Batch 400 Loss 2.160613\n",
      "Epoch 1 Loss 0.3408\n",
      "Time taken for 1 epoch 6325.29056930542 sec\n",
      "\n",
      "Epoch 1 Loss 0.3416\n",
      "Time taken for 1 epoch 6337.746527433395 sec\n",
      "\n",
      "Epoch 1 Loss 0.3426\n",
      "Time taken for 1 epoch 6352.091728448868 sec\n",
      "\n",
      "Epoch 1 Loss 0.3430\n",
      "Time taken for 1 epoch 6363.864728927612 sec\n",
      "\n",
      "Epoch 1 Loss 0.3435\n",
      "Time taken for 1 epoch 6399.515730142593 sec\n",
      "\n",
      "Epoch 1 Loss 0.3445\n",
      "Time taken for 1 epoch 6416.351509571075 sec\n",
      "\n",
      "Epoch 1 Loss 0.3454\n",
      "Time taken for 1 epoch 6433.119819879532 sec\n",
      "\n",
      "Epoch 1 Loss 0.3462\n",
      "Time taken for 1 epoch 6447.141985177994 sec\n",
      "\n",
      "Epoch 1 Loss 0.3467\n",
      "Time taken for 1 epoch 6462.842184782028 sec\n",
      "\n",
      "Epoch 1 Loss 0.3474\n",
      "Time taken for 1 epoch 6477.35933637619 sec\n",
      "\n",
      "Epoch 1 Loss 0.3482\n",
      "Time taken for 1 epoch 6490.309624910355 sec\n",
      "\n",
      "Epoch 1 Loss 0.3490\n",
      "Time taken for 1 epoch 6509.246723890305 sec\n",
      "\n",
      "Epoch 1 Loss 0.3495\n",
      "Time taken for 1 epoch 6524.333187580109 sec\n",
      "\n",
      "Epoch 1 Loss 0.3505\n",
      "Time taken for 1 epoch 6543.556189537048 sec\n",
      "\n",
      "Epoch 1 Loss 0.3512\n",
      "Time taken for 1 epoch 6561.9030418396 sec\n",
      "\n",
      "Epoch 1 Loss 0.3520\n",
      "Time taken for 1 epoch 6576.863284111023 sec\n",
      "\n",
      "Epoch 1 Loss 0.3529\n",
      "Time taken for 1 epoch 6596.199378728867 sec\n",
      "\n",
      "Epoch 1 Loss 0.3538\n",
      "Time taken for 1 epoch 6610.257785558701 sec\n",
      "\n",
      "Epoch 1 Loss 0.3547\n",
      "Time taken for 1 epoch 6624.424923658371 sec\n",
      "\n",
      "Epoch 1 Loss 0.3554\n",
      "Time taken for 1 epoch 6637.60492348671 sec\n",
      "\n",
      "Epoch 1 Loss 0.3564\n",
      "Time taken for 1 epoch 6650.528924703598 sec\n",
      "\n",
      "Epoch 1 Loss 0.3573\n",
      "Time taken for 1 epoch 6664.799482584 sec\n",
      "\n",
      "Epoch 1 Loss 0.3581\n",
      "Time taken for 1 epoch 6680.879675865173 sec\n",
      "\n",
      "Epoch 1 Loss 0.3592\n",
      "Time taken for 1 epoch 6695.3556962013245 sec\n",
      "\n",
      "Epoch 1 Loss 0.3600\n",
      "Time taken for 1 epoch 6708.540694475174 sec\n",
      "\n",
      "Epoch 1 Loss 0.3611\n",
      "Time taken for 1 epoch 6726.704835653305 sec\n",
      "\n",
      "Epoch 1 Loss 0.3622\n",
      "Time taken for 1 epoch 6741.534865617752 sec\n",
      "\n",
      "Epoch 1 Loss 0.3630\n",
      "Time taken for 1 epoch 6756.436145067215 sec\n",
      "\n",
      "Epoch 1 Loss 0.3640\n",
      "Time taken for 1 epoch 6772.383601903915 sec\n",
      "\n",
      "Epoch 1 Loss 0.3647\n",
      "Time taken for 1 epoch 6786.018711566925 sec\n",
      "\n",
      "Epoch 1 Loss 0.3654\n",
      "Time taken for 1 epoch 6804.519003152847 sec\n",
      "\n",
      "Epoch 1 Loss 0.3660\n",
      "Time taken for 1 epoch 6818.326896190643 sec\n",
      "\n",
      "Epoch 1 Loss 0.3670\n",
      "Time taken for 1 epoch 6835.071175575256 sec\n",
      "\n",
      "Epoch 1 Loss 0.3678\n",
      "Time taken for 1 epoch 6849.808008670807 sec\n",
      "\n",
      "Epoch 1 Loss 0.3683\n",
      "Time taken for 1 epoch 6861.824569940567 sec\n",
      "\n",
      "Epoch 1 Loss 0.3691\n",
      "Time taken for 1 epoch 6877.370376110077 sec\n",
      "\n",
      "Epoch 1 Loss 0.3699\n",
      "Time taken for 1 epoch 6890.890376806259 sec\n",
      "\n",
      "Epoch 1 Loss 0.3712\n",
      "Time taken for 1 epoch 6906.647268533707 sec\n",
      "\n",
      "Epoch 1 Loss 0.3723\n",
      "Time taken for 1 epoch 6920.663750886917 sec\n",
      "\n",
      "Epoch 1 Loss 0.3727\n",
      "Time taken for 1 epoch 6936.704750537872 sec\n",
      "\n",
      "Epoch 1 Loss 0.3739\n",
      "Time taken for 1 epoch 6952.800430059433 sec\n",
      "\n",
      "Epoch 1 Loss 0.3748\n",
      "Time taken for 1 epoch 6969.258427858353 sec\n",
      "\n",
      "Epoch 1 Loss 0.3758\n",
      "Time taken for 1 epoch 6986.216304302216 sec\n",
      "\n",
      "Epoch 1 Loss 0.3766\n",
      "Time taken for 1 epoch 6999.2984030246735 sec\n",
      "\n",
      "Epoch 1 Loss 0.3777\n",
      "Time taken for 1 epoch 7016.259942770004 sec\n",
      "\n",
      "Epoch 1 Loss 0.3782\n",
      "Time taken for 1 epoch 7028.1239540576935 sec\n",
      "\n",
      "Epoch 1 Loss 0.3790\n",
      "Time taken for 1 epoch 7040.122956752777 sec\n",
      "\n",
      "Epoch 1 Loss 0.3798\n",
      "Time taken for 1 epoch 7053.887956380844 sec\n",
      "\n",
      "Epoch 1 Loss 0.3807\n",
      "Time taken for 1 epoch 7066.617957115173 sec\n",
      "\n",
      "Epoch 1 Loss 0.3813\n",
      "Time taken for 1 epoch 7079.535955905914 sec\n",
      "\n",
      "Epoch 1 Loss 0.3821\n",
      "Time taken for 1 epoch 7092.682039022446 sec\n",
      "\n",
      "Epoch 1 Loss 0.3829\n",
      "Time taken for 1 epoch 7105.298038244247 sec\n",
      "\n",
      "Epoch 1 Loss 0.3834\n",
      "Time taken for 1 epoch 7118.0604474544525 sec\n",
      "\n",
      "Epoch 1 Loss 0.3845\n",
      "Time taken for 1 epoch 7134.059446811676 sec\n",
      "\n",
      "Epoch 1 Loss 0.3853\n",
      "Time taken for 1 epoch 7150.287491083145 sec\n",
      "\n",
      "Epoch 1 Loss 0.3859\n",
      "Time taken for 1 epoch 7164.400490522385 sec\n",
      "\n",
      "Epoch 1 Loss 0.3864\n",
      "Time taken for 1 epoch 7176.498878479004 sec\n",
      "\n",
      "Epoch 1 Loss 0.3873\n",
      "Time taken for 1 epoch 7191.905066490173 sec\n",
      "\n",
      "Epoch 1 Loss 0.3880\n",
      "Time taken for 1 epoch 7206.00387096405 sec\n",
      "\n",
      "Epoch 1 Loss 0.3890\n",
      "Time taken for 1 epoch 7220.293881416321 sec\n",
      "\n",
      "Epoch 1 Loss 0.3899\n",
      "Time taken for 1 epoch 7235.273881196976 sec\n",
      "\n",
      "Epoch 1 Loss 0.3907\n",
      "Time taken for 1 epoch 7247.925462245941 sec\n",
      "\n",
      "Epoch 1 Loss 0.3914\n",
      "Time taken for 1 epoch 7259.93270611763 sec\n",
      "\n",
      "Epoch 1 Loss 0.3923\n",
      "Time taken for 1 epoch 7274.316248655319 sec\n",
      "\n",
      "Epoch 1 Loss 0.3930\n",
      "Time taken for 1 epoch 7288.2692494392395 sec\n",
      "\n",
      "Epoch 1 Loss 0.3938\n",
      "Time taken for 1 epoch 7302.0172481536865 sec\n",
      "\n",
      "Epoch 1 Loss 0.3943\n",
      "Time taken for 1 epoch 7314.985249996185 sec\n",
      "\n",
      "Epoch 1 Loss 0.3952\n",
      "Time taken for 1 epoch 7333.7351150512695 sec\n",
      "\n",
      "Epoch 1 Loss 0.3959\n",
      "Time taken for 1 epoch 7348.297785282135 sec\n",
      "\n",
      "Epoch 1 Loss 0.3968\n",
      "Time taken for 1 epoch 7361.3298370838165 sec\n",
      "\n",
      "Epoch 1 Loss 0.3976\n",
      "Time taken for 1 epoch 7375.652133226395 sec\n",
      "\n",
      "Epoch 1 Loss 0.3984\n",
      "Time taken for 1 epoch 7388.937798976898 sec\n",
      "\n",
      "Epoch 1 Loss 0.3991\n",
      "Time taken for 1 epoch 7404.177521944046 sec\n",
      "\n",
      "Epoch 1 Loss 0.4000\n",
      "Time taken for 1 epoch 7416.61652135849 sec\n",
      "\n",
      "Epoch 1 Loss 0.4007\n",
      "Time taken for 1 epoch 7429.578087091446 sec\n",
      "\n",
      "Epoch 1 Loss 0.4016\n",
      "Time taken for 1 epoch 7444.284098625183 sec\n",
      "\n",
      "Epoch 1 Loss 0.4028\n",
      "Time taken for 1 epoch 7460.411561727524 sec\n",
      "\n",
      "Epoch 1 Loss 0.4034\n",
      "Time taken for 1 epoch 7474.773115634918 sec\n",
      "\n",
      "Epoch 1 Loss 0.4040\n",
      "Time taken for 1 epoch 7489.015115737915 sec\n",
      "\n",
      "Epoch 1 Loss 0.4047\n",
      "Time taken for 1 epoch 7502.3991158008575 sec\n",
      "\n",
      "Epoch 1 Loss 0.4059\n",
      "Time taken for 1 epoch 7519.897657632828 sec\n",
      "\n",
      "Epoch 1 Loss 0.4067\n",
      "Time taken for 1 epoch 7535.287608623505 sec\n",
      "\n",
      "Epoch 1 Loss 0.4076\n",
      "Time taken for 1 epoch 7551.337607622147 sec\n",
      "\n",
      "Epoch 1 Loss 0.4081\n",
      "Time taken for 1 epoch 7563.282167434692 sec\n",
      "\n",
      "Epoch 1 Loss 0.4091\n",
      "Time taken for 1 epoch 7580.580319643021 sec\n",
      "\n",
      "Epoch 1 Loss 0.4095\n",
      "Time taken for 1 epoch 7594.402888774872 sec\n",
      "\n",
      "Epoch 1 Loss 0.4103\n",
      "Time taken for 1 epoch 7609.646885871887 sec\n",
      "\n",
      "Epoch 1 Loss 0.4117\n",
      "Time taken for 1 epoch 7625.178508520126 sec\n",
      "\n",
      "Epoch 1 Loss 0.4124\n",
      "Time taken for 1 epoch 7637.949805259705 sec\n",
      "\n",
      "Epoch 1 Loss 0.4131\n",
      "Time taken for 1 epoch 7650.900492191315 sec\n",
      "\n",
      "Epoch 1 Loss 0.4138\n",
      "Time taken for 1 epoch 7664.319489955902 sec\n",
      "\n",
      "Epoch 1 Loss 0.4146\n",
      "Time taken for 1 epoch 7676.796900510788 sec\n",
      "\n",
      "Epoch 1 Loss 0.4152\n",
      "Time taken for 1 epoch 7690.123901128769 sec\n",
      "\n",
      "Epoch 1 Loss 0.4163\n",
      "Time taken for 1 epoch 7706.220129489899 sec\n",
      "\n",
      "Epoch 1 Loss 0.4169\n",
      "Time taken for 1 epoch 7720.314128875732 sec\n",
      "\n",
      "Epoch 1 Loss 0.4176\n",
      "Time taken for 1 epoch 7731.6191284656525 sec\n",
      "\n",
      "Epoch 1 Loss 0.4182\n",
      "Time taken for 1 epoch 7743.838130474091 sec\n",
      "\n",
      "Epoch 1 Loss 0.4192\n",
      "Time taken for 1 epoch 7760.811747550964 sec\n",
      "\n",
      "Epoch 1 Loss 0.4197\n",
      "Time taken for 1 epoch 7772.495748281479 sec\n",
      "\n",
      "Epoch 1 Loss 0.4206\n",
      "Time taken for 1 epoch 7786.684759140015 sec\n",
      "\n",
      "Epoch 1 Batch 500 Loss 3.183510\n",
      "Epoch 1 Loss 0.4214\n",
      "Time taken for 1 epoch 7799.383159399033 sec\n",
      "\n",
      "Epoch 1 Loss 0.4221\n",
      "Time taken for 1 epoch 7813.170154571533 sec\n",
      "\n",
      "Epoch 1 Loss 0.4227\n",
      "Time taken for 1 epoch 7824.673587799072 sec\n",
      "\n",
      "Epoch 1 Loss 0.4233\n",
      "Time taken for 1 epoch 7838.827587127686 sec\n",
      "\n",
      "Epoch 1 Loss 0.4240\n",
      "Time taken for 1 epoch 7851.345588445663 sec\n",
      "\n",
      "Epoch 1 Loss 0.4247\n",
      "Time taken for 1 epoch 7865.417588472366 sec\n",
      "\n",
      "Epoch 1 Loss 0.4253\n",
      "Time taken for 1 epoch 7877.286588191986 sec\n",
      "\n",
      "Epoch 1 Loss 0.4265\n",
      "Time taken for 1 epoch 7896.73109793663 sec\n",
      "\n",
      "Epoch 1 Loss 0.4274\n",
      "Time taken for 1 epoch 7909.340620517731 sec\n",
      "\n",
      "Epoch 1 Loss 0.4281\n",
      "Time taken for 1 epoch 7922.839617967606 sec\n",
      "\n",
      "Epoch 1 Loss 0.4289\n",
      "Time taken for 1 epoch 7938.288620710373 sec\n",
      "\n",
      "Epoch 1 Loss 0.4297\n",
      "Time taken for 1 epoch 7953.345375299454 sec\n",
      "\n",
      "Epoch 1 Loss 0.4306\n",
      "Time taken for 1 epoch 7966.944809436798 sec\n",
      "\n",
      "Epoch 1 Loss 0.4313\n",
      "Time taken for 1 epoch 7980.869810581207 sec\n",
      "\n",
      "Epoch 1 Loss 0.4321\n",
      "Time taken for 1 epoch 7998.906842947006 sec\n",
      "\n",
      "Epoch 1 Loss 0.4328\n",
      "Time taken for 1 epoch 8012.411080121994 sec\n",
      "\n",
      "Epoch 1 Loss 0.4335\n",
      "Time taken for 1 epoch 8030.380855321884 sec\n",
      "\n",
      "Epoch 1 Loss 0.4342\n",
      "Time taken for 1 epoch 8045.199854373932 sec\n",
      "\n",
      "Epoch 1 Loss 0.4349\n",
      "Time taken for 1 epoch 8058.831372261047 sec\n",
      "\n",
      "Epoch 1 Loss 0.4357\n",
      "Time taken for 1 epoch 8074.4833726882935 sec\n",
      "\n",
      "Epoch 1 Loss 0.4364\n",
      "Time taken for 1 epoch 8087.174993515015 sec\n",
      "\n",
      "Epoch 1 Loss 0.4369\n",
      "Time taken for 1 epoch 8100.661995172501 sec\n",
      "\n",
      "Epoch 1 Loss 0.4378\n",
      "Time taken for 1 epoch 8115.606314659119 sec\n",
      "\n",
      "Epoch 1 Loss 0.4388\n",
      "Time taken for 1 epoch 8130.61034822464 sec\n",
      "\n",
      "Epoch 1 Loss 0.4397\n",
      "Time taken for 1 epoch 8143.84889626503 sec\n",
      "\n",
      "Epoch 1 Loss 0.4406\n",
      "Time taken for 1 epoch 8158.13689661026 sec\n",
      "\n",
      "Epoch 1 Loss 0.4416\n",
      "Time taken for 1 epoch 8176.269521713257 sec\n",
      "\n",
      "Epoch 1 Loss 0.4429\n",
      "Time taken for 1 epoch 8192.017590045929 sec\n",
      "\n",
      "Epoch 1 Loss 0.4441\n",
      "Time taken for 1 epoch 8209.756670951843 sec\n",
      "\n",
      "Epoch 1 Loss 0.4450\n",
      "Time taken for 1 epoch 8224.673613548279 sec\n",
      "\n",
      "Epoch 1 Loss 0.4458\n",
      "Time taken for 1 epoch 8242.421552658081 sec\n",
      "\n",
      "Epoch 1 Loss 0.4465\n",
      "Time taken for 1 epoch 8256.649215698242 sec\n",
      "\n",
      "Epoch 1 Loss 0.4474\n",
      "Time taken for 1 epoch 8271.782258033752 sec\n",
      "\n",
      "Epoch 1 Loss 0.4479\n",
      "Time taken for 1 epoch 8283.58125782013 sec\n",
      "\n",
      "Epoch 1 Loss 0.4489\n",
      "Time taken for 1 epoch 8304.370258569717 sec\n",
      "\n",
      "Epoch 1 Loss 0.4495\n",
      "Time taken for 1 epoch 8316.839257955551 sec\n",
      "\n",
      "Epoch 1 Loss 0.4504\n",
      "Time taken for 1 epoch 8334.176907539368 sec\n",
      "\n",
      "Epoch 1 Loss 0.4512\n",
      "Time taken for 1 epoch 8347.560090303421 sec\n",
      "\n",
      "Epoch 1 Loss 0.4517\n",
      "Time taken for 1 epoch 8362.52509021759 sec\n",
      "\n",
      "Epoch 1 Loss 0.4526\n",
      "Time taken for 1 epoch 8383.317762374878 sec\n",
      "\n",
      "Epoch 1 Loss 0.4531\n",
      "Time taken for 1 epoch 8398.861022233963 sec\n",
      "\n",
      "Epoch 1 Loss 0.4535\n",
      "Time taken for 1 epoch 8410.008020877838 sec\n",
      "\n",
      "Epoch 1 Loss 0.4545\n",
      "Time taken for 1 epoch 8423.889024019241 sec\n",
      "\n",
      "Epoch 1 Loss 0.4555\n",
      "Time taken for 1 epoch 8441.408020973206 sec\n",
      "\n",
      "Epoch 1 Loss 0.4563\n",
      "Time taken for 1 epoch 8454.74651646614 sec\n",
      "\n",
      "Epoch 1 Loss 0.4576\n",
      "Time taken for 1 epoch 8470.580873966217 sec\n",
      "\n",
      "Epoch 1 Loss 0.4582\n",
      "Time taken for 1 epoch 8484.764871835709 sec\n",
      "\n",
      "Epoch 1 Loss 0.4591\n",
      "Time taken for 1 epoch 8499.6868724823 sec\n",
      "\n",
      "Epoch 1 Loss 0.4596\n",
      "Time taken for 1 epoch 8510.598873376846 sec\n",
      "\n",
      "Epoch 1 Loss 0.4605\n",
      "Time taken for 1 epoch 8530.530434846878 sec\n",
      "\n",
      "Epoch 1 Loss 0.4612\n",
      "Time taken for 1 epoch 8545.712268829346 sec\n",
      "\n",
      "Epoch 1 Loss 0.4621\n",
      "Time taken for 1 epoch 8560.54726934433 sec\n",
      "\n",
      "Epoch 1 Loss 0.4631\n",
      "Time taken for 1 epoch 8576.451278924942 sec\n",
      "\n",
      "Epoch 1 Loss 0.4638\n",
      "Time taken for 1 epoch 8592.424191951752 sec\n",
      "\n",
      "Epoch 1 Loss 0.4643\n",
      "Time taken for 1 epoch 8605.567886590958 sec\n",
      "\n",
      "Epoch 1 Loss 0.4653\n",
      "Time taken for 1 epoch 8621.098240852356 sec\n",
      "\n",
      "Epoch 1 Loss 0.4662\n",
      "Time taken for 1 epoch 8636.584741353989 sec\n",
      "\n",
      "Epoch 1 Loss 0.4668\n",
      "Time taken for 1 epoch 8649.565476417542 sec\n",
      "\n",
      "Epoch 1 Loss 0.4677\n",
      "Time taken for 1 epoch 8664.985116481781 sec\n",
      "\n",
      "Epoch 1 Loss 0.4687\n",
      "Time taken for 1 epoch 8680.332688808441 sec\n",
      "\n",
      "Epoch 1 Loss 0.4695\n",
      "Time taken for 1 epoch 8692.91968870163 sec\n",
      "\n",
      "Epoch 1 Loss 0.4702\n",
      "Time taken for 1 epoch 8706.458688735962 sec\n",
      "\n",
      "Epoch 1 Loss 0.4711\n",
      "Time taken for 1 epoch 8720.787484645844 sec\n",
      "\n",
      "Epoch 1 Loss 0.4716\n",
      "Time taken for 1 epoch 8736.015483379364 sec\n",
      "\n",
      "Epoch 1 Loss 0.4726\n",
      "Time taken for 1 epoch 8751.665276527405 sec\n",
      "\n",
      "Epoch 1 Loss 0.4734\n",
      "Time taken for 1 epoch 8765.437278270721 sec\n",
      "\n",
      "Epoch 1 Loss 0.4741\n",
      "Time taken for 1 epoch 8781.156791448593 sec\n",
      "\n",
      "Epoch 1 Loss 0.4746\n",
      "Time taken for 1 epoch 8793.712789535522 sec\n",
      "\n",
      "Epoch 1 Loss 0.4752\n",
      "Time taken for 1 epoch 8806.870789289474 sec\n",
      "\n",
      "Epoch 1 Loss 0.4759\n",
      "Time taken for 1 epoch 8819.464790821075 sec\n",
      "\n",
      "Epoch 1 Loss 0.4770\n",
      "Time taken for 1 epoch 8833.839791297913 sec\n",
      "\n",
      "Epoch 1 Loss 0.4779\n",
      "Time taken for 1 epoch 8847.4745054245 sec\n",
      "\n",
      "Epoch 1 Loss 0.4788\n",
      "Time taken for 1 epoch 8861.71038722992 sec\n",
      "\n",
      "Epoch 1 Loss 0.4799\n",
      "Time taken for 1 epoch 8879.410420894623 sec\n",
      "\n",
      "Epoch 1 Loss 0.4808\n",
      "Time taken for 1 epoch 8892.325409173965 sec\n",
      "\n",
      "Epoch 1 Loss 0.4814\n",
      "Time taken for 1 epoch 8907.635409116745 sec\n",
      "\n",
      "Epoch 1 Loss 0.4818\n",
      "Time taken for 1 epoch 8921.116822481155 sec\n",
      "\n",
      "Epoch 1 Loss 0.4827\n",
      "Time taken for 1 epoch 8938.093295574188 sec\n",
      "\n",
      "Epoch 1 Loss 0.4835\n",
      "Time taken for 1 epoch 8953.775868415833 sec\n",
      "\n",
      "Epoch 1 Loss 0.4842\n",
      "Time taken for 1 epoch 8969.576891183853 sec\n",
      "\n",
      "Epoch 1 Loss 0.4851\n",
      "Time taken for 1 epoch 8986.790197610855 sec\n",
      "\n",
      "Epoch 1 Loss 0.4858\n",
      "Time taken for 1 epoch 9001.668197393417 sec\n",
      "\n",
      "Epoch 1 Loss 0.4873\n",
      "Time taken for 1 epoch 9018.64313673973 sec\n",
      "\n",
      "Epoch 1 Loss 0.4881\n",
      "Time taken for 1 epoch 9032.16974568367 sec\n",
      "\n",
      "Epoch 1 Loss 0.4890\n",
      "Time taken for 1 epoch 9046.442440748215 sec\n",
      "\n",
      "Epoch 1 Loss 0.4900\n",
      "Time taken for 1 epoch 9059.860095262527 sec\n",
      "\n",
      "Epoch 1 Loss 0.4908\n",
      "Time taken for 1 epoch 9073.319396972656 sec\n",
      "\n",
      "Epoch 1 Loss 0.4920\n",
      "Time taken for 1 epoch 9089.483065843582 sec\n",
      "\n",
      "Epoch 1 Loss 0.4926\n",
      "Time taken for 1 epoch 9100.841065645218 sec\n",
      "\n",
      "Epoch 1 Loss 0.4937\n",
      "Time taken for 1 epoch 9118.213068008423 sec\n",
      "\n",
      "Epoch 1 Loss 0.4946\n",
      "Time taken for 1 epoch 9131.750883102417 sec\n",
      "\n",
      "Epoch 1 Loss 0.4953\n",
      "Time taken for 1 epoch 9144.798882722855 sec\n",
      "\n",
      "Epoch 1 Loss 0.4960\n",
      "Time taken for 1 epoch 9156.646884918213 sec\n",
      "\n",
      "Epoch 1 Loss 0.4967\n",
      "Time taken for 1 epoch 9172.896582365036 sec\n",
      "\n",
      "Epoch 1 Loss 0.4973\n",
      "Time taken for 1 epoch 9193.607363700867 sec\n",
      "\n",
      "Epoch 1 Loss 0.4980\n",
      "Time taken for 1 epoch 9205.412340641022 sec\n",
      "\n",
      "Epoch 1 Loss 0.4987\n",
      "Time taken for 1 epoch 9220.590427875519 sec\n",
      "\n",
      "Epoch 1 Loss 0.4996\n",
      "Time taken for 1 epoch 9239.318160057068 sec\n",
      "\n",
      "Epoch 1 Loss 0.5001\n",
      "Time taken for 1 epoch 9253.586967229843 sec\n",
      "\n",
      "Epoch 1 Loss 0.5012\n",
      "Time taken for 1 epoch 9267.070056915283 sec\n",
      "\n",
      "Epoch 1 Batch 600 Loss 2.922731\n",
      "Epoch 1 Loss 0.5019\n",
      "Time taken for 1 epoch 9278.747783899307 sec\n",
      "\n",
      "Epoch 1 Loss 0.5028\n",
      "Time taken for 1 epoch 9295.871680259705 sec\n",
      "\n",
      "Epoch 1 Loss 0.5036\n",
      "Time taken for 1 epoch 9309.98668050766 sec\n",
      "\n",
      "Epoch 1 Loss 0.5044\n",
      "Time taken for 1 epoch 9325.099679470062 sec\n",
      "\n",
      "Epoch 1 Loss 0.5051\n",
      "Time taken for 1 epoch 9340.978678226471 sec\n",
      "\n",
      "Epoch 1 Loss 0.5056\n",
      "Time taken for 1 epoch 9377.872559785843 sec\n",
      "\n",
      "Epoch 1 Loss 0.5068\n",
      "Time taken for 1 epoch 9393.46377825737 sec\n",
      "\n",
      "Epoch 1 Loss 0.5077\n",
      "Time taken for 1 epoch 9409.313523292542 sec\n",
      "\n",
      "Epoch 1 Loss 0.5089\n",
      "Time taken for 1 epoch 9423.991038799286 sec\n",
      "\n",
      "Epoch 1 Loss 0.5098\n",
      "Time taken for 1 epoch 9440.072521686554 sec\n",
      "\n",
      "Epoch 1 Loss 0.5105\n",
      "Time taken for 1 epoch 9456.180170059204 sec\n",
      "\n",
      "Epoch 1 Loss 0.5112\n",
      "Time taken for 1 epoch 9468.512464046478 sec\n",
      "\n",
      "Epoch 1 Loss 0.5119\n",
      "Time taken for 1 epoch 9482.519243001938 sec\n",
      "\n",
      "Epoch 1 Loss 0.5129\n",
      "Time taken for 1 epoch 9497.832245111465 sec\n",
      "\n",
      "Epoch 1 Loss 0.5138\n",
      "Time taken for 1 epoch 9514.563989162445 sec\n",
      "\n",
      "Epoch 1 Loss 0.5144\n",
      "Time taken for 1 epoch 9525.429532766342 sec\n",
      "\n",
      "Epoch 1 Loss 0.5149\n",
      "Time taken for 1 epoch 9540.816830158234 sec\n",
      "\n",
      "Epoch 1 Loss 0.5159\n",
      "Time taken for 1 epoch 9557.83298420906 sec\n",
      "\n",
      "Epoch 1 Loss 0.5167\n",
      "Time taken for 1 epoch 9570.675205945969 sec\n",
      "\n",
      "Epoch 1 Loss 0.5173\n",
      "Time taken for 1 epoch 9586.016295909882 sec\n",
      "\n",
      "Epoch 1 Loss 0.5182\n",
      "Time taken for 1 epoch 9599.673623800278 sec\n",
      "\n",
      "Epoch 1 Loss 0.5190\n",
      "Time taken for 1 epoch 9618.185625076294 sec\n",
      "\n",
      "Epoch 1 Loss 0.5201\n",
      "Time taken for 1 epoch 9631.809955835342 sec\n",
      "\n",
      "Epoch 1 Loss 0.5209\n",
      "Time taken for 1 epoch 9647.73834180832 sec\n",
      "\n",
      "Epoch 1 Loss 0.5218\n",
      "Time taken for 1 epoch 9660.528083086014 sec\n",
      "\n",
      "Epoch 1 Loss 0.5223\n",
      "Time taken for 1 epoch 9672.513084888458 sec\n",
      "\n",
      "Epoch 1 Loss 0.5236\n",
      "Time taken for 1 epoch 9687.858810901642 sec\n",
      "\n",
      "Epoch 1 Loss 0.5244\n",
      "Time taken for 1 epoch 9703.460661411285 sec\n",
      "\n",
      "Epoch 1 Loss 0.5251\n",
      "Time taken for 1 epoch 9717.884814739227 sec\n",
      "\n",
      "Epoch 1 Loss 0.5258\n",
      "Time taken for 1 epoch 9732.415816545486 sec\n",
      "\n",
      "Epoch 1 Loss 0.5265\n",
      "Time taken for 1 epoch 9745.962814807892 sec\n",
      "\n",
      "Epoch 1 Loss 0.5275\n",
      "Time taken for 1 epoch 9761.335836410522 sec\n",
      "\n",
      "Epoch 1 Loss 0.5280\n",
      "Time taken for 1 epoch 9772.511836767197 sec\n",
      "\n",
      "Epoch 1 Loss 0.5288\n",
      "Time taken for 1 epoch 9786.673835039139 sec\n",
      "\n",
      "Epoch 1 Loss 0.5294\n",
      "Time taken for 1 epoch 9799.542834758759 sec\n",
      "\n",
      "Epoch 1 Loss 0.5302\n",
      "Time taken for 1 epoch 9813.541836500168 sec\n",
      "\n",
      "Epoch 1 Loss 0.5312\n",
      "Time taken for 1 epoch 9829.183327436447 sec\n",
      "\n",
      "Epoch 1 Loss 0.5320\n",
      "Time taken for 1 epoch 9843.21131014824 sec\n",
      "\n",
      "Epoch 1 Loss 0.5329\n",
      "Time taken for 1 epoch 9858.68331003189 sec\n",
      "\n",
      "Epoch 1 Loss 0.5339\n",
      "Time taken for 1 epoch 9874.051310539246 sec\n",
      "\n",
      "Epoch 1 Loss 0.5348\n",
      "Time taken for 1 epoch 9889.010113954544 sec\n",
      "\n",
      "Epoch 1 Loss 0.5356\n",
      "Time taken for 1 epoch 9902.539142131805 sec\n",
      "\n",
      "Epoch 1 Loss 0.5361\n",
      "Time taken for 1 epoch 9918.224141597748 sec\n",
      "\n",
      "Epoch 1 Loss 0.5371\n",
      "Time taken for 1 epoch 9933.838418483734 sec\n",
      "\n",
      "Epoch 1 Loss 0.5377\n",
      "Time taken for 1 epoch 9948.972487449646 sec\n",
      "\n",
      "Epoch 1 Loss 0.5385\n",
      "Time taken for 1 epoch 9961.609488725662 sec\n",
      "\n",
      "Epoch 1 Loss 0.5394\n",
      "Time taken for 1 epoch 9976.297486543655 sec\n",
      "\n",
      "Epoch 1 Loss 0.5402\n",
      "Time taken for 1 epoch 9990.14148592949 sec\n",
      "\n",
      "Epoch 1 Loss 0.5411\n",
      "Time taken for 1 epoch 10003.312486886978 sec\n",
      "\n",
      "Epoch 1 Loss 0.5420\n",
      "Time taken for 1 epoch 10018.810110092163 sec\n",
      "\n",
      "Epoch 1 Loss 0.5431\n",
      "Time taken for 1 epoch 10032.375769376755 sec\n",
      "\n",
      "Epoch 1 Loss 0.5440\n",
      "Time taken for 1 epoch 10047.080767393112 sec\n",
      "\n",
      "Epoch 1 Loss 0.5450\n",
      "Time taken for 1 epoch 10065.55176782608 sec\n",
      "\n",
      "Epoch 1 Loss 0.5461\n",
      "Time taken for 1 epoch 10080.415595054626 sec\n",
      "\n",
      "Epoch 1 Loss 0.5468\n",
      "Time taken for 1 epoch 10097.967276573181 sec\n",
      "\n",
      "Epoch 1 Loss 0.5476\n",
      "Time taken for 1 epoch 10112.388568878174 sec\n",
      "\n",
      "Epoch 1 Loss 0.5485\n",
      "Time taken for 1 epoch 10127.613091945648 sec\n",
      "\n",
      "Epoch 1 Loss 0.5492\n",
      "Time taken for 1 epoch 10140.568092107773 sec\n",
      "\n",
      "Epoch 1 Loss 0.5500\n",
      "Time taken for 1 epoch 10153.435092926025 sec\n",
      "\n",
      "Epoch 1 Loss 0.5510\n",
      "Time taken for 1 epoch 10172.077380180359 sec\n",
      "\n",
      "Epoch 1 Loss 0.5516\n",
      "Time taken for 1 epoch 10185.887380361557 sec\n",
      "\n",
      "Epoch 1 Loss 0.5525\n",
      "Time taken for 1 epoch 10200.00937962532 sec\n",
      "\n",
      "Epoch 1 Loss 0.5535\n",
      "Time taken for 1 epoch 10215.77439236641 sec\n",
      "\n",
      "Epoch 1 Loss 0.5544\n",
      "Time taken for 1 epoch 10230.245201349258 sec\n",
      "\n",
      "Epoch 1 Loss 0.5554\n",
      "Time taken for 1 epoch 10246.258621454239 sec\n",
      "\n",
      "Epoch 1 Loss 0.5558\n",
      "Time taken for 1 epoch 10261.37862086296 sec\n",
      "\n",
      "Epoch 1 Loss 0.5570\n",
      "Time taken for 1 epoch 10275.198724746704 sec\n",
      "\n",
      "Epoch 1 Loss 0.5579\n",
      "Time taken for 1 epoch 10292.495843172073 sec\n",
      "\n",
      "Epoch 1 Loss 0.5588\n",
      "Time taken for 1 epoch 10311.873421669006 sec\n",
      "\n",
      "Epoch 1 Loss 0.5597\n",
      "Time taken for 1 epoch 10325.043664455414 sec\n",
      "\n",
      "Epoch 1 Loss 0.5607\n",
      "Time taken for 1 epoch 10338.924818515778 sec\n",
      "\n",
      "Epoch 1 Loss 0.5617\n",
      "Time taken for 1 epoch 10353.12956571579 sec\n",
      "\n",
      "Epoch 1 Loss 0.5625\n",
      "Time taken for 1 epoch 10368.007566452026 sec\n",
      "\n",
      "Epoch 1 Loss 0.5631\n",
      "Time taken for 1 epoch 10383.442501544952 sec\n",
      "\n",
      "Epoch 1 Loss 0.5638\n",
      "Time taken for 1 epoch 10402.313544750214 sec\n",
      "\n",
      "Epoch 1 Loss 0.5645\n",
      "Time taken for 1 epoch 10417.62613272667 sec\n",
      "\n",
      "Epoch 1 Loss 0.5652\n",
      "Time taken for 1 epoch 10436.122218132019 sec\n",
      "\n",
      "Epoch 1 Loss 0.5661\n",
      "Time taken for 1 epoch 10451.463220596313 sec\n",
      "\n",
      "Epoch 1 Loss 0.5671\n",
      "Time taken for 1 epoch 10469.934070110321 sec\n",
      "\n",
      "Epoch 1 Loss 0.5680\n",
      "Time taken for 1 epoch 10487.324082374573 sec\n",
      "\n",
      "Epoch 1 Loss 0.5689\n",
      "Time taken for 1 epoch 10505.180730819702 sec\n",
      "\n",
      "Epoch 1 Loss 0.5700\n",
      "Time taken for 1 epoch 10525.666729211807 sec\n",
      "\n",
      "Epoch 1 Loss 0.5706\n",
      "Time taken for 1 epoch 10559.673189163208 sec\n",
      "\n",
      "Epoch 1 Loss 0.5717\n",
      "Time taken for 1 epoch 10576.05052280426 sec\n",
      "\n",
      "Epoch 1 Loss 0.5725\n",
      "Time taken for 1 epoch 10611.837047815323 sec\n",
      "\n",
      "Epoch 1 Loss 0.5733\n",
      "Time taken for 1 epoch 10627.315421104431 sec\n",
      "\n",
      "Epoch 1 Loss 0.5738\n",
      "Time taken for 1 epoch 10642.182687282562 sec\n",
      "\n",
      "Epoch 1 Loss 0.5749\n",
      "Time taken for 1 epoch 10669.669763803482 sec\n",
      "\n",
      "Epoch 1 Loss 0.5757\n",
      "Time taken for 1 epoch 10684.050259113312 sec\n",
      "\n",
      "Epoch 1 Loss 0.5767\n",
      "Time taken for 1 epoch 10698.504258871078 sec\n",
      "\n",
      "Epoch 1 Loss 0.5778\n",
      "Time taken for 1 epoch 10718.425261259079 sec\n",
      "\n",
      "Epoch 1 Loss 0.5787\n",
      "Time taken for 1 epoch 10734.110846281052 sec\n",
      "\n",
      "Epoch 1 Loss 0.5796\n",
      "Time taken for 1 epoch 10750.240993976593 sec\n",
      "\n",
      "Epoch 1 Loss 0.5807\n",
      "Time taken for 1 epoch 10763.798413991928 sec\n",
      "\n",
      "Epoch 1 Loss 0.5816\n",
      "Time taken for 1 epoch 10778.181777954102 sec\n",
      "\n",
      "Epoch 1 Loss 0.5823\n",
      "Time taken for 1 epoch 10792.647387742996 sec\n",
      "\n",
      "Epoch 1 Loss 0.5831\n",
      "Time taken for 1 epoch 10807.09638762474 sec\n",
      "\n",
      "Epoch 1 Loss 0.5838\n",
      "Time taken for 1 epoch 10822.205724716187 sec\n",
      "\n",
      "Epoch 1 Loss 0.5847\n",
      "Time taken for 1 epoch 10836.643726587296 sec\n",
      "\n",
      "Epoch 1 Loss 0.5853\n",
      "Time taken for 1 epoch 10849.116417884827 sec\n",
      "\n",
      "Epoch 1 Batch 700 Loss 2.773489\n",
      "Epoch 1 Loss 0.5860\n",
      "Time taken for 1 epoch 10861.992005348206 sec\n",
      "\n",
      "Epoch 1 Loss 0.5870\n",
      "Time taken for 1 epoch 10879.582877635956 sec\n",
      "\n",
      "Epoch 1 Loss 0.5878\n",
      "Time taken for 1 epoch 10892.75087594986 sec\n",
      "\n",
      "Epoch 1 Loss 0.5885\n",
      "Time taken for 1 epoch 10907.149335861206 sec\n",
      "\n",
      "Epoch 1 Loss 0.5896\n",
      "Time taken for 1 epoch 10923.826001644135 sec\n",
      "\n",
      "Epoch 1 Loss 0.5904\n",
      "Time taken for 1 epoch 10936.833840847015 sec\n",
      "\n",
      "Epoch 1 Loss 0.5913\n",
      "Time taken for 1 epoch 10951.808840036392 sec\n",
      "\n",
      "Epoch 1 Loss 0.5919\n",
      "Time taken for 1 epoch 10966.804839849472 sec\n",
      "\n",
      "Epoch 1 Loss 0.5925\n",
      "Time taken for 1 epoch 10980.589187860489 sec\n",
      "\n",
      "Epoch 1 Loss 0.5931\n",
      "Time taken for 1 epoch 10994.713186264038 sec\n",
      "\n",
      "Epoch 1 Loss 0.5939\n",
      "Time taken for 1 epoch 11011.322246551514 sec\n",
      "\n",
      "Epoch 1 Loss 0.5950\n",
      "Time taken for 1 epoch 11027.40524673462 sec\n",
      "\n",
      "Epoch 1 Loss 0.5955\n",
      "Time taken for 1 epoch 11040.892246484756 sec\n",
      "\n",
      "Epoch 1 Loss 0.5963\n",
      "Time taken for 1 epoch 11055.865092515945 sec\n",
      "\n",
      "Epoch 1 Loss 0.5971\n",
      "Time taken for 1 epoch 11070.991445064545 sec\n",
      "\n",
      "Epoch 1 Loss 0.5977\n",
      "Time taken for 1 epoch 11085.512444972992 sec\n",
      "\n",
      "Epoch 1 Loss 0.5987\n",
      "Time taken for 1 epoch 11098.972198724747 sec\n",
      "\n",
      "Epoch 1 Loss 0.5994\n",
      "Time taken for 1 epoch 11110.91565656662 sec\n",
      "\n",
      "Epoch 1 Loss 0.6001\n",
      "Time taken for 1 epoch 11124.173656463623 sec\n",
      "\n",
      "Epoch 1 Loss 0.6009\n",
      "Time taken for 1 epoch 11137.422924518585 sec\n",
      "\n",
      "Epoch 1 Loss 0.6016\n",
      "Time taken for 1 epoch 11150.424442768097 sec\n",
      "\n",
      "Epoch 1 Loss 0.6022\n",
      "Time taken for 1 epoch 11162.44030046463 sec\n",
      "\n",
      "Epoch 1 Loss 0.6026\n",
      "Time taken for 1 epoch 11176.760963439941 sec\n",
      "\n",
      "Epoch 1 Loss 0.6036\n",
      "Time taken for 1 epoch 11189.7464761734 sec\n",
      "\n",
      "Epoch 1 Loss 0.6045\n",
      "Time taken for 1 epoch 11203.620475053787 sec\n",
      "\n",
      "Epoch 1 Loss 0.6051\n",
      "Time taken for 1 epoch 11216.055040597916 sec\n",
      "\n",
      "Epoch 1 Loss 0.6060\n",
      "Time taken for 1 epoch 11230.912408351898 sec\n",
      "\n",
      "Epoch 1 Loss 0.6066\n",
      "Time taken for 1 epoch 11244.186409235 sec\n",
      "\n",
      "Epoch 1 Loss 0.6074\n",
      "Time taken for 1 epoch 11259.25840830803 sec\n",
      "\n",
      "Epoch 1 Loss 0.6083\n",
      "Time taken for 1 epoch 11273.833958148956 sec\n",
      "\n",
      "Epoch 1 Loss 0.6092\n",
      "Time taken for 1 epoch 11290.675450325012 sec\n",
      "\n",
      "Epoch 1 Loss 0.6100\n",
      "Time taken for 1 epoch 11304.107664108276 sec\n",
      "\n",
      "Epoch 1 Loss 0.6107\n",
      "Time taken for 1 epoch 11320.552518606186 sec\n",
      "\n",
      "Epoch 1 Loss 0.6113\n",
      "Time taken for 1 epoch 11336.147865056992 sec\n",
      "\n",
      "Epoch 1 Loss 0.6121\n",
      "Time taken for 1 epoch 11350.736517906189 sec\n",
      "\n",
      "Epoch 1 Loss 0.6131\n",
      "Time taken for 1 epoch 11364.587850093842 sec\n",
      "\n",
      "Epoch 1 Loss 0.6141\n",
      "Time taken for 1 epoch 11380.353949785233 sec\n",
      "\n",
      "Epoch 1 Loss 0.6148\n",
      "Time taken for 1 epoch 11394.715781450272 sec\n",
      "\n",
      "Epoch 1 Loss 0.6157\n",
      "Time taken for 1 epoch 11408.317781925201 sec\n",
      "\n",
      "Epoch 1 Loss 0.6167\n",
      "Time taken for 1 epoch 11422.586374998093 sec\n",
      "\n",
      "Epoch 1 Loss 0.6177\n",
      "Time taken for 1 epoch 11437.426270484924 sec\n",
      "\n",
      "Epoch 1 Loss 0.6184\n",
      "Time taken for 1 epoch 11452.435704946518 sec\n",
      "\n",
      "Epoch 1 Loss 0.6194\n",
      "Time taken for 1 epoch 11467.616337299347 sec\n",
      "\n",
      "Epoch 1 Loss 0.6200\n",
      "Time taken for 1 epoch 11483.70386838913 sec\n",
      "\n",
      "Epoch 1 Loss 0.6209\n",
      "Time taken for 1 epoch 11499.40140414238 sec\n",
      "\n",
      "Epoch 1 Loss 0.6218\n",
      "Time taken for 1 epoch 11511.520975589752 sec\n",
      "\n",
      "Epoch 1 Loss 0.6233\n",
      "Time taken for 1 epoch 11529.336383342743 sec\n",
      "\n",
      "Epoch 1 Loss 0.6243\n",
      "Time taken for 1 epoch 11544.088977336884 sec\n",
      "\n",
      "Epoch 1 Loss 0.6250\n",
      "Time taken for 1 epoch 11558.689108371735 sec\n",
      "\n",
      "Epoch 1 Loss 0.6258\n",
      "Time taken for 1 epoch 11574.640669107437 sec\n",
      "\n",
      "Epoch 1 Loss 0.6264\n",
      "Time taken for 1 epoch 11588.989210128784 sec\n",
      "\n",
      "Epoch 1 Loss 0.6274\n",
      "Time taken for 1 epoch 11609.172769069672 sec\n",
      "\n",
      "Epoch 1 Loss 0.6282\n",
      "Time taken for 1 epoch 11625.1081533432 sec\n",
      "\n",
      "Epoch 1 Loss 0.6291\n",
      "Time taken for 1 epoch 11638.038306236267 sec\n",
      "\n",
      "Epoch 1 Loss 0.6298\n",
      "Time taken for 1 epoch 11653.182444095612 sec\n",
      "\n",
      "Epoch 1 Loss 0.6305\n",
      "Time taken for 1 epoch 11665.879979610443 sec\n",
      "\n",
      "Epoch 1 Loss 0.6314\n",
      "Time taken for 1 epoch 11684.710352420807 sec\n",
      "\n",
      "Epoch 1 Loss 0.6320\n",
      "Time taken for 1 epoch 11699.306314945221 sec\n",
      "\n",
      "Epoch 1 Loss 0.6330\n",
      "Time taken for 1 epoch 11725.924790620804 sec\n",
      "\n",
      "Epoch 1 Loss 0.6340\n",
      "Time taken for 1 epoch 11755.060550928116 sec\n",
      "\n",
      "Epoch 1 Loss 0.6349\n",
      "Time taken for 1 epoch 11769.11412024498 sec\n",
      "\n",
      "Epoch 1 Loss 0.6357\n",
      "Time taken for 1 epoch 11782.419838666916 sec\n",
      "\n",
      "Epoch 1 Loss 0.6367\n",
      "Time taken for 1 epoch 11798.183254241943 sec\n",
      "\n",
      "Epoch 1 Loss 0.6375\n",
      "Time taken for 1 epoch 11813.699494600296 sec\n",
      "\n",
      "Epoch 1 Loss 0.6382\n",
      "Time taken for 1 epoch 11828.441642045975 sec\n",
      "\n",
      "Epoch 1 Loss 0.6390\n",
      "Time taken for 1 epoch 11849.096476316452 sec\n",
      "\n",
      "Epoch 1 Loss 0.6397\n",
      "Time taken for 1 epoch 11863.73121547699 sec\n",
      "\n",
      "Epoch 1 Loss 0.6405\n",
      "Time taken for 1 epoch 11878.309117794037 sec\n",
      "\n",
      "Epoch 1 Loss 0.6411\n",
      "Time taken for 1 epoch 11891.304817438126 sec\n",
      "\n",
      "Epoch 1 Loss 0.6419\n",
      "Time taken for 1 epoch 11906.631296873093 sec\n",
      "\n",
      "Epoch 1 Loss 0.6425\n",
      "Time taken for 1 epoch 11922.48340845108 sec\n",
      "\n",
      "Epoch 1 Loss 0.6434\n",
      "Time taken for 1 epoch 11939.634440422058 sec\n",
      "\n",
      "Epoch 1 Loss 0.6442\n",
      "Time taken for 1 epoch 11957.592137813568 sec\n",
      "\n",
      "Epoch 1 Loss 0.6456\n",
      "Time taken for 1 epoch 11977.991394758224 sec\n",
      "\n",
      "Epoch 1 Loss 0.6468\n",
      "Time taken for 1 epoch 11997.406558275223 sec\n",
      "\n",
      "Epoch 1 Loss 0.6474\n",
      "Time taken for 1 epoch 12012.8319606781 sec\n",
      "\n",
      "Epoch 1 Loss 0.6480\n",
      "Time taken for 1 epoch 12029.137474060059 sec\n",
      "\n",
      "Epoch 1 Loss 0.6487\n",
      "Time taken for 1 epoch 12042.84243440628 sec\n",
      "\n",
      "Epoch 1 Loss 0.6494\n",
      "Time taken for 1 epoch 12055.623545646667 sec\n",
      "\n",
      "Epoch 1 Loss 0.6501\n",
      "Time taken for 1 epoch 12072.606255292892 sec\n",
      "\n",
      "Epoch 1 Loss 0.6507\n",
      "Time taken for 1 epoch 12085.955607652664 sec\n",
      "\n",
      "Epoch 1 Loss 0.6512\n",
      "Time taken for 1 epoch 12101.63314962387 sec\n",
      "\n",
      "Epoch 1 Loss 0.6519\n",
      "Time taken for 1 epoch 12117.870500087738 sec\n",
      "\n",
      "Epoch 1 Loss 0.6527\n",
      "Time taken for 1 epoch 12132.809525489807 sec\n",
      "\n",
      "Epoch 1 Loss 0.6534\n",
      "Time taken for 1 epoch 12147.307782649994 sec\n",
      "\n",
      "Epoch 1 Loss 0.6541\n",
      "Time taken for 1 epoch 12165.311605453491 sec\n",
      "\n",
      "Epoch 1 Loss 0.6551\n",
      "Time taken for 1 epoch 12179.895514249802 sec\n",
      "\n",
      "Epoch 1 Loss 0.6560\n",
      "Time taken for 1 epoch 12196.00081205368 sec\n",
      "\n",
      "Epoch 1 Loss 0.6572\n",
      "Time taken for 1 epoch 12210.344260692596 sec\n",
      "\n",
      "Epoch 1 Loss 0.6582\n",
      "Time taken for 1 epoch 12224.001996278763 sec\n",
      "\n",
      "Epoch 1 Loss 0.6589\n",
      "Time taken for 1 epoch 12246.433671236038 sec\n",
      "\n",
      "Epoch 1 Loss 0.6595\n",
      "Time taken for 1 epoch 12262.937556505203 sec\n",
      "\n",
      "Epoch 1 Loss 0.6602\n",
      "Time taken for 1 epoch 12280.418992757797 sec\n",
      "\n",
      "Epoch 1 Loss 0.6609\n",
      "Time taken for 1 epoch 12295.613295555115 sec\n",
      "\n",
      "Epoch 1 Loss 0.6615\n",
      "Time taken for 1 epoch 12310.577221393585 sec\n",
      "\n",
      "Epoch 1 Loss 0.6622\n",
      "Time taken for 1 epoch 12326.008175611496 sec\n",
      "\n",
      "Epoch 1 Loss 0.6633\n",
      "Time taken for 1 epoch 12341.096578359604 sec\n",
      "\n",
      "Epoch 1 Loss 0.6643\n",
      "Time taken for 1 epoch 12357.397456645966 sec\n",
      "\n",
      "Epoch 1 Loss 0.6649\n",
      "Time taken for 1 epoch 12370.585901737213 sec\n",
      "\n",
      "Epoch 1 Loss 0.6658\n",
      "Time taken for 1 epoch 12387.596714496613 sec\n",
      "\n",
      "Epoch 1 Batch 800 Loss 3.037612\n",
      "Epoch 1 Loss 0.6666\n",
      "Time taken for 1 epoch 12402.272952318192 sec\n",
      "\n",
      "Epoch 1 Loss 0.6672\n",
      "Time taken for 1 epoch 12416.807713747025 sec\n",
      "\n",
      "Epoch 1 Loss 0.6678\n",
      "Time taken for 1 epoch 12430.861434936523 sec\n",
      "\n",
      "Epoch 1 Loss 0.6686\n",
      "Time taken for 1 epoch 12445.578838825226 sec\n",
      "\n",
      "Epoch 1 Loss 0.6694\n",
      "Time taken for 1 epoch 12459.138238430023 sec\n",
      "\n",
      "Epoch 1 Loss 0.6701\n",
      "Time taken for 1 epoch 12475.95196390152 sec\n",
      "\n",
      "Epoch 1 Loss 0.6707\n",
      "Time taken for 1 epoch 12489.745926618576 sec\n",
      "\n",
      "Epoch 1 Loss 0.6715\n",
      "Time taken for 1 epoch 12507.722340345383 sec\n",
      "\n",
      "Epoch 1 Loss 0.6725\n",
      "Time taken for 1 epoch 12524.21008849144 sec\n",
      "\n",
      "Epoch 1 Loss 0.6731\n",
      "Time taken for 1 epoch 12535.63789319992 sec\n",
      "\n",
      "Epoch 1 Loss 0.6736\n",
      "Time taken for 1 epoch 12549.754912614822 sec\n",
      "\n",
      "Epoch 1 Loss 0.6746\n",
      "Time taken for 1 epoch 12565.092165708542 sec\n",
      "\n",
      "Epoch 1 Loss 0.6752\n",
      "Time taken for 1 epoch 12578.453749656677 sec\n",
      "\n",
      "Epoch 1 Loss 0.6759\n",
      "Time taken for 1 epoch 12596.531982183456 sec\n",
      "\n",
      "Epoch 1 Loss 0.6770\n",
      "Time taken for 1 epoch 12612.240495681763 sec\n",
      "\n",
      "Epoch 1 Loss 0.6777\n",
      "Time taken for 1 epoch 12627.288580656052 sec\n",
      "\n",
      "Epoch 1 Loss 0.6787\n",
      "Time taken for 1 epoch 12641.639579057693 sec\n",
      "\n",
      "Epoch 1 Loss 0.6797\n",
      "Time taken for 1 epoch 12656.779361009598 sec\n",
      "\n",
      "Epoch 1 Loss 0.6807\n",
      "Time taken for 1 epoch 12674.227417945862 sec\n",
      "\n",
      "Epoch 1 Loss 0.6812\n",
      "Time taken for 1 epoch 12685.536763191223 sec\n",
      "\n",
      "Epoch 1 Loss 0.6819\n",
      "Time taken for 1 epoch 12700.04187631607 sec\n",
      "\n",
      "Epoch 1 Loss 0.6828\n",
      "Time taken for 1 epoch 12712.913375139236 sec\n",
      "\n",
      "Epoch 1 Loss 0.6834\n",
      "Time taken for 1 epoch 12728.58638548851 sec\n",
      "\n",
      "Epoch 1 Loss 0.6842\n",
      "Time taken for 1 epoch 12741.646738529205 sec\n",
      "\n",
      "Epoch 1 Loss 0.6850\n",
      "Time taken for 1 epoch 12760.298401355743 sec\n",
      "\n",
      "Epoch 1 Loss 0.6859\n",
      "Time taken for 1 epoch 12774.254488945007 sec\n",
      "\n",
      "Epoch 1 Loss 0.6870\n",
      "Time taken for 1 epoch 12790.955819368362 sec\n",
      "\n",
      "Epoch 1 Loss 0.6880\n",
      "Time taken for 1 epoch 12803.76344037056 sec\n",
      "\n",
      "Epoch 1 Loss 0.6885\n",
      "Time taken for 1 epoch 12816.429572343826 sec\n",
      "\n",
      "Epoch 1 Loss 0.6890\n",
      "Time taken for 1 epoch 12829.414949178696 sec\n",
      "\n",
      "Epoch 1 Loss 0.6899\n",
      "Time taken for 1 epoch 12845.418722867966 sec\n",
      "\n",
      "Epoch 1 Loss 0.6907\n",
      "Time taken for 1 epoch 12861.686182975769 sec\n",
      "\n",
      "Epoch 1 Loss 0.6918\n",
      "Time taken for 1 epoch 12877.816684961319 sec\n",
      "\n",
      "Epoch 1 Loss 0.6925\n",
      "Time taken for 1 epoch 12892.99888420105 sec\n",
      "\n",
      "Epoch 1 Loss 0.6933\n",
      "Time taken for 1 epoch 12907.248119592667 sec\n",
      "\n",
      "Epoch 1 Loss 0.6939\n",
      "Time taken for 1 epoch 12920.413922309875 sec\n",
      "\n",
      "Epoch 1 Loss 0.6953\n",
      "Time taken for 1 epoch 12938.416395425797 sec\n",
      "\n",
      "Epoch 1 Loss 0.6964\n",
      "Time taken for 1 epoch 12952.958604097366 sec\n",
      "\n",
      "Epoch 1 Loss 0.6968\n",
      "Time taken for 1 epoch 12965.740056991577 sec\n",
      "\n",
      "Epoch 1 Loss 0.6974\n",
      "Time taken for 1 epoch 12981.197792291641 sec\n",
      "\n",
      "Epoch 1 Loss 0.6983\n",
      "Time taken for 1 epoch 12999.280496358871 sec\n",
      "\n",
      "Epoch 1 Loss 0.6992\n",
      "Time taken for 1 epoch 13016.831127405167 sec\n",
      "\n",
      "Epoch 1 Loss 0.7001\n",
      "Time taken for 1 epoch 13028.677775859833 sec\n",
      "\n",
      "Epoch 1 Loss 0.7009\n",
      "Time taken for 1 epoch 13042.833437681198 sec\n",
      "\n",
      "Epoch 1 Loss 0.7019\n",
      "Time taken for 1 epoch 13056.70443701744 sec\n",
      "\n",
      "Epoch 1 Loss 0.7029\n",
      "Time taken for 1 epoch 13068.582508325577 sec\n",
      "\n",
      "Epoch 1 Loss 0.7037\n",
      "Time taken for 1 epoch 13081.819595098495 sec\n",
      "\n",
      "Epoch 1 Loss 0.7046\n",
      "Time taken for 1 epoch 13101.943360805511 sec\n",
      "\n",
      "Epoch 1 Loss 0.7055\n",
      "Time taken for 1 epoch 13116.243800640106 sec\n",
      "\n",
      "Epoch 1 Loss 0.7062\n",
      "Time taken for 1 epoch 13129.654497861862 sec\n",
      "\n",
      "Epoch 1 Loss 0.7071\n",
      "Time taken for 1 epoch 13145.285007715225 sec\n",
      "\n",
      "Epoch 1 Loss 0.7076\n",
      "Time taken for 1 epoch 13162.795110940933 sec\n",
      "\n",
      "Epoch 1 Loss 0.7082\n",
      "Time taken for 1 epoch 13179.119953155518 sec\n",
      "\n",
      "Epoch 1 Loss 0.7092\n",
      "Time taken for 1 epoch 13196.419811725616 sec\n",
      "\n",
      "Epoch 1 Loss 0.7100\n",
      "Time taken for 1 epoch 13212.862881183624 sec\n",
      "\n",
      "Epoch 1 Loss 0.7108\n",
      "Time taken for 1 epoch 13228.2820250988 sec\n",
      "\n",
      "Epoch 1 Loss 0.7114\n",
      "Time taken for 1 epoch 13247.028071403503 sec\n",
      "\n",
      "Epoch 1 Loss 0.7124\n",
      "Time taken for 1 epoch 13260.548577308655 sec\n",
      "\n",
      "Epoch 1 Loss 0.7136\n",
      "Time taken for 1 epoch 13277.826157093048 sec\n",
      "\n",
      "Epoch 1 Loss 0.7147\n",
      "Time taken for 1 epoch 13294.14702129364 sec\n",
      "\n",
      "Epoch 1 Loss 0.7157\n",
      "Time taken for 1 epoch 13311.235562324524 sec\n",
      "\n",
      "Epoch 1 Loss 0.7163\n",
      "Time taken for 1 epoch 13329.936972618103 sec\n",
      "\n",
      "Epoch 1 Loss 0.7169\n",
      "Time taken for 1 epoch 13345.07982134819 sec\n",
      "\n",
      "Epoch 1 Loss 0.7178\n",
      "Time taken for 1 epoch 13359.601465702057 sec\n",
      "\n",
      "Epoch 1 Loss 0.7185\n",
      "Time taken for 1 epoch 13375.373960971832 sec\n",
      "\n",
      "Epoch 1 Loss 0.7194\n",
      "Time taken for 1 epoch 13392.748339891434 sec\n",
      "\n",
      "Epoch 1 Loss 0.7203\n",
      "Time taken for 1 epoch 13406.34187912941 sec\n",
      "\n",
      "Epoch 1 Loss 0.7210\n",
      "Time taken for 1 epoch 13422.719892501831 sec\n",
      "\n",
      "Epoch 1 Loss 0.7217\n",
      "Time taken for 1 epoch 13439.126588821411 sec\n",
      "\n",
      "Epoch 1 Loss 0.7223\n",
      "Time taken for 1 epoch 13452.504994392395 sec\n",
      "\n",
      "Epoch 1 Loss 0.7229\n",
      "Time taken for 1 epoch 13468.45438504219 sec\n",
      "\n",
      "Epoch 1 Loss 0.7238\n",
      "Time taken for 1 epoch 13483.340698003769 sec\n",
      "\n",
      "Epoch 1 Loss 0.7244\n",
      "Time taken for 1 epoch 13500.434789896011 sec\n",
      "\n",
      "Epoch 1 Loss 0.7252\n",
      "Time taken for 1 epoch 13516.113690853119 sec\n",
      "\n",
      "Epoch 1 Loss 0.7258\n",
      "Time taken for 1 epoch 13529.56749033928 sec\n",
      "\n",
      "Epoch 1 Loss 0.7265\n",
      "Time taken for 1 epoch 13542.215473413467 sec\n",
      "\n",
      "Epoch 1 Loss 0.7275\n",
      "Time taken for 1 epoch 13558.062793016434 sec\n",
      "\n",
      "Epoch 1 Loss 0.7285\n",
      "Time taken for 1 epoch 13575.016021728516 sec\n",
      "\n",
      "Epoch 1 Loss 0.7297\n",
      "Time taken for 1 epoch 13589.724516868591 sec\n",
      "\n",
      "Epoch 1 Loss 0.7303\n",
      "Time taken for 1 epoch 13603.166541337967 sec\n",
      "\n",
      "Epoch 1 Loss 0.7310\n",
      "Time taken for 1 epoch 13615.264026165009 sec\n",
      "\n",
      "Epoch 1 Loss 0.7319\n",
      "Time taken for 1 epoch 13632.69037103653 sec\n",
      "\n",
      "Epoch 1 Loss 0.7325\n",
      "Time taken for 1 epoch 13645.078923940659 sec\n",
      "\n",
      "Epoch 1 Loss 0.7334\n",
      "Time taken for 1 epoch 13661.358035087585 sec\n",
      "\n",
      "Epoch 1 Loss 0.7344\n",
      "Time taken for 1 epoch 13676.64519071579 sec\n",
      "\n",
      "Epoch 1 Loss 0.7349\n",
      "Time taken for 1 epoch 13691.687193393707 sec\n",
      "\n",
      "Epoch 1 Loss 0.7358\n",
      "Time taken for 1 epoch 13712.030064821243 sec\n",
      "\n",
      "Epoch 1 Loss 0.7368\n",
      "Time taken for 1 epoch 13727.5425157547 sec\n",
      "\n",
      "Epoch 1 Loss 0.7380\n",
      "Time taken for 1 epoch 13744.607545375824 sec\n",
      "\n",
      "Epoch 1 Loss 0.7388\n",
      "Time taken for 1 epoch 13758.495545625687 sec\n",
      "\n",
      "Epoch 1 Loss 0.7397\n",
      "Time taken for 1 epoch 13775.086819171906 sec\n",
      "\n",
      "Epoch 1 Loss 0.7403\n",
      "Time taken for 1 epoch 13789.37470817566 sec\n",
      "\n",
      "Epoch 1 Loss 0.7410\n",
      "Time taken for 1 epoch 13803.217324733734 sec\n",
      "\n",
      "Epoch 1 Loss 0.7421\n",
      "Time taken for 1 epoch 13821.728323698044 sec\n",
      "\n",
      "Epoch 1 Loss 0.7426\n",
      "Time taken for 1 epoch 13835.387519836426 sec\n",
      "\n",
      "Epoch 1 Loss 0.7432\n",
      "Time taken for 1 epoch 13850.621097803116 sec\n",
      "\n",
      "Epoch 1 Loss 0.7442\n",
      "Time taken for 1 epoch 13864.513901233673 sec\n",
      "\n",
      "Epoch 1 Loss 0.7446\n",
      "Time taken for 1 epoch 13879.915444850922 sec\n",
      "\n",
      "Epoch 1 Loss 0.7454\n",
      "Time taken for 1 epoch 13895.915302753448 sec\n",
      "\n",
      "Epoch 1 Loss 0.7463\n",
      "Time taken for 1 epoch 13912.182999134064 sec\n",
      "\n",
      "Epoch 1 Batch 900 Loss 2.501126\n",
      "Epoch 1 Loss 0.7469\n",
      "Time taken for 1 epoch 13924.362131118774 sec\n",
      "\n",
      "Epoch 1 Loss 0.7481\n",
      "Time taken for 1 epoch 13938.932093858719 sec\n",
      "\n",
      "Epoch 1 Loss 0.7489\n",
      "Time taken for 1 epoch 13953.99009346962 sec\n",
      "\n",
      "Epoch 1 Loss 0.7498\n",
      "Time taken for 1 epoch 13972.033540010452 sec\n",
      "\n",
      "Epoch 1 Loss 0.7506\n",
      "Time taken for 1 epoch 13984.209536790848 sec\n",
      "\n",
      "Epoch 1 Loss 0.7518\n",
      "Time taken for 1 epoch 14003.122152805328 sec\n",
      "\n",
      "Epoch 1 Loss 0.7526\n",
      "Time taken for 1 epoch 14016.942863464355 sec\n",
      "\n",
      "Epoch 1 Loss 0.7531\n",
      "Time taken for 1 epoch 14030.087863445282 sec\n",
      "\n",
      "Epoch 1 Loss 0.7541\n",
      "Time taken for 1 epoch 14049.643421173096 sec\n",
      "\n",
      "Epoch 1 Loss 0.7546\n",
      "Time taken for 1 epoch 14066.48179936409 sec\n",
      "\n",
      "Epoch 1 Loss 0.7556\n",
      "Time taken for 1 epoch 14099.33922791481 sec\n",
      "\n",
      "Epoch 1 Loss 0.7566\n",
      "Time taken for 1 epoch 14116.992561101913 sec\n",
      "\n",
      "Epoch 1 Loss 0.7576\n",
      "Time taken for 1 epoch 14133.092962741852 sec\n",
      "\n",
      "Epoch 1 Loss 0.7585\n",
      "Time taken for 1 epoch 14150.253482818604 sec\n",
      "\n",
      "Epoch 1 Loss 0.7590\n",
      "Time taken for 1 epoch 14165.141559362411 sec\n",
      "\n",
      "Epoch 1 Loss 0.7595\n",
      "Time taken for 1 epoch 14179.801342725754 sec\n",
      "\n",
      "Epoch 1 Loss 0.7601\n",
      "Time taken for 1 epoch 14191.031326770782 sec\n",
      "\n",
      "Epoch 1 Loss 0.7609\n",
      "Time taken for 1 epoch 14209.217187166214 sec\n",
      "\n",
      "Epoch 1 Loss 0.7616\n",
      "Time taken for 1 epoch 14226.401716709137 sec\n",
      "\n",
      "Epoch 1 Loss 0.7619\n",
      "Time taken for 1 epoch 14240.422718763351 sec\n",
      "\n",
      "Epoch 1 Loss 0.7626\n",
      "Time taken for 1 epoch 14254.148716211319 sec\n",
      "\n",
      "Epoch 1 Loss 0.7633\n",
      "Time taken for 1 epoch 14268.045716762543 sec\n",
      "\n",
      "Epoch 1 Loss 0.7640\n",
      "Time taken for 1 epoch 14279.335717201233 sec\n",
      "\n",
      "Epoch 1 Loss 0.7648\n",
      "Time taken for 1 epoch 14293.85070014 sec\n",
      "\n",
      "Epoch 1 Loss 0.7657\n",
      "Time taken for 1 epoch 14309.32902765274 sec\n",
      "\n",
      "Epoch 1 Loss 0.7665\n",
      "Time taken for 1 epoch 14323.7730281353 sec\n",
      "\n",
      "Epoch 1 Loss 0.7673\n",
      "Time taken for 1 epoch 14336.78402853012 sec\n",
      "\n",
      "Epoch 1 Loss 0.7683\n",
      "Time taken for 1 epoch 14350.991039037704 sec\n",
      "\n",
      "Epoch 1 Loss 0.7688\n",
      "Time taken for 1 epoch 14363.93152475357 sec\n",
      "\n",
      "Epoch 1 Loss 0.7699\n",
      "Time taken for 1 epoch 14384.786395549774 sec\n",
      "\n",
      "Epoch 1 Loss 0.7705\n",
      "Time taken for 1 epoch 14396.219783306122 sec\n",
      "\n",
      "Epoch 1 Loss 0.7714\n",
      "Time taken for 1 epoch 14413.275060415268 sec\n",
      "\n",
      "Epoch 1 Loss 0.7721\n",
      "Time taken for 1 epoch 14432.069562911987 sec\n",
      "\n",
      "Epoch 1 Loss 0.7731\n",
      "Time taken for 1 epoch 14448.48849773407 sec\n",
      "\n",
      "Epoch 1 Loss 0.7739\n",
      "Time taken for 1 epoch 14465.634499788284 sec\n",
      "\n",
      "Epoch 1 Loss 0.7747\n",
      "Time taken for 1 epoch 14478.524497509003 sec\n",
      "\n",
      "Epoch 1 Loss 0.7757\n",
      "Time taken for 1 epoch 14494.720870256424 sec\n",
      "\n",
      "Epoch 1 Loss 0.7762\n",
      "Time taken for 1 epoch 14505.951040506363 sec\n",
      "\n",
      "Epoch 1 Loss 0.7771\n",
      "Time taken for 1 epoch 14520.690040588379 sec\n",
      "\n",
      "Epoch 1 Loss 0.7779\n",
      "Time taken for 1 epoch 14536.429040670395 sec\n",
      "\n",
      "Epoch 1 Loss 0.7787\n",
      "Time taken for 1 epoch 14551.608740568161 sec\n",
      "\n",
      "Epoch 1 Loss 0.7792\n",
      "Time taken for 1 epoch 14566.97750878334 sec\n",
      "\n",
      "Epoch 1 Loss 0.7802\n",
      "Time taken for 1 epoch 14583.343022108078 sec\n",
      "\n",
      "Epoch 1 Loss 0.7807\n",
      "Time taken for 1 epoch 14595.616022109985 sec\n",
      "\n",
      "Epoch 1 Loss 0.7819\n",
      "Time taken for 1 epoch 14611.07869386673 sec\n",
      "\n",
      "Epoch 1 Loss 0.7827\n",
      "Time taken for 1 epoch 14625.348638057709 sec\n",
      "\n",
      "Epoch 1 Loss 0.7835\n",
      "Time taken for 1 epoch 14643.970429182053 sec\n",
      "\n",
      "Epoch 1 Loss 0.7843\n",
      "Time taken for 1 epoch 14658.106609582901 sec\n",
      "\n",
      "Epoch 1 Loss 0.7849\n",
      "Time taken for 1 epoch 14670.701845645905 sec\n",
      "\n",
      "Epoch 1 Loss 0.7855\n",
      "Time taken for 1 epoch 14684.136275053024 sec\n",
      "\n",
      "Epoch 1 Loss 0.7861\n",
      "Time taken for 1 epoch 14696.772898197174 sec\n",
      "\n",
      "Epoch 1 Loss 0.7866\n",
      "Time taken for 1 epoch 14711.309592485428 sec\n",
      "\n",
      "Epoch 1 Loss 0.7876\n",
      "Time taken for 1 epoch 14730.199389219284 sec\n",
      "\n",
      "Epoch 1 Loss 0.7888\n",
      "Time taken for 1 epoch 14746.605522632599 sec\n",
      "\n",
      "Epoch 1 Loss 0.7897\n",
      "Time taken for 1 epoch 14760.352522611618 sec\n",
      "\n",
      "Epoch 1 Loss 0.7903\n",
      "Time taken for 1 epoch 14775.440748214722 sec\n",
      "\n",
      "Epoch 1 Loss 0.7909\n",
      "Time taken for 1 epoch 14790.175649166107 sec\n",
      "\n",
      "Epoch 1 Loss 0.7917\n",
      "Time taken for 1 epoch 14803.456167936325 sec\n",
      "\n",
      "Epoch 1 Loss 0.7928\n",
      "Time taken for 1 epoch 14821.221122264862 sec\n",
      "\n",
      "Epoch 1 Loss 0.7934\n",
      "Time taken for 1 epoch 14834.653325557709 sec\n",
      "\n",
      "Epoch 1 Loss 0.7942\n",
      "Time taken for 1 epoch 14852.439424753189 sec\n",
      "\n",
      "Epoch 1 Loss 0.7947\n",
      "Time taken for 1 epoch 14864.352343320847 sec\n",
      "\n",
      "Epoch 1 Loss 0.7959\n",
      "Time taken for 1 epoch 14879.945085763931 sec\n",
      "\n",
      "Epoch 1 Loss 0.7968\n",
      "Time taken for 1 epoch 14892.806084632874 sec\n",
      "\n",
      "Epoch 1 Loss 0.7974\n",
      "Time taken for 1 epoch 14906.887809991837 sec\n",
      "\n",
      "Epoch 1 Loss 0.7982\n",
      "Time taken for 1 epoch 14922.3026907444 sec\n",
      "\n",
      "Epoch 1 Loss 0.7988\n",
      "Time taken for 1 epoch 14934.68677353859 sec\n",
      "\n",
      "Epoch 1 Loss 0.7995\n",
      "Time taken for 1 epoch 14946.527428627014 sec\n",
      "\n",
      "Epoch 1 Loss 0.8009\n",
      "Time taken for 1 epoch 14966.433981895447 sec\n",
      "\n",
      "Epoch 1 Loss 0.8017\n",
      "Time taken for 1 epoch 14978.607261419296 sec\n",
      "\n",
      "Epoch 1 Loss 0.8022\n",
      "Time taken for 1 epoch 14990.64588880539 sec\n",
      "\n",
      "Epoch 1 Loss 0.8029\n",
      "Time taken for 1 epoch 15005.009892463684 sec\n",
      "\n",
      "Epoch 1 Loss 0.8037\n",
      "Time taken for 1 epoch 15018.486256599426 sec\n",
      "\n",
      "Epoch 1 Loss 0.8043\n",
      "Time taken for 1 epoch 15035.643022298813 sec\n",
      "\n",
      "Epoch 1 Loss 0.8051\n",
      "Time taken for 1 epoch 15051.355217456818 sec\n",
      "\n",
      "Epoch 1 Loss 0.8058\n",
      "Time taken for 1 epoch 15067.76701927185 sec\n",
      "\n",
      "Epoch 1 Loss 0.8067\n",
      "Time taken for 1 epoch 15084.223023891449 sec\n",
      "\n",
      "Epoch 1 Loss 0.8076\n",
      "Time taken for 1 epoch 15098.93170428276 sec\n",
      "\n",
      "Epoch 1 Loss 0.8087\n",
      "Time taken for 1 epoch 15113.995286941528 sec\n",
      "\n",
      "Epoch 1 Loss 0.8094\n",
      "Time taken for 1 epoch 15131.310511112213 sec\n",
      "\n",
      "Epoch 1 Loss 0.8101\n",
      "Time taken for 1 epoch 15144.240607976913 sec\n",
      "\n",
      "Epoch 1 Loss 0.8110\n",
      "Time taken for 1 epoch 15161.790327072144 sec\n",
      "\n",
      "Epoch 1 Loss 0.8118\n",
      "Time taken for 1 epoch 15175.117758989334 sec\n",
      "\n",
      "Epoch 1 Loss 0.8126\n",
      "Time taken for 1 epoch 15188.744617700577 sec\n",
      "\n",
      "Epoch 1 Loss 0.8133\n",
      "Time taken for 1 epoch 15202.848869085312 sec\n",
      "\n",
      "Epoch 1 Loss 0.8140\n",
      "Time taken for 1 epoch 15216.292103528976 sec\n",
      "\n",
      "Epoch 1 Loss 0.8149\n",
      "Time taken for 1 epoch 15233.431139469147 sec\n",
      "\n",
      "Epoch 1 Loss 0.8157\n",
      "Time taken for 1 epoch 15250.968575239182 sec\n",
      "\n",
      "Epoch 1 Loss 0.8163\n",
      "Time taken for 1 epoch 15264.332577466965 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(\"Epoch {} Batch {} Loss {:4f}\".format(\n",
    "                epoch + 1, batch, batch_loss.numpy()))\n",
    "\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            # checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "            manager.save()\n",
    "\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                            total_loss / steps_per_epoch))\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "        \n",
    "# ResourceExhaustedError: Graph execution error 발생 => https://www.pythonfixing.com/2022/05/fixed-tensorflow-invalidargumenterror.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_ko, max_length_ch))\n",
    "\n",
    "    sentence = preprocess_ch(sentence)\n",
    "    inputs = [ch_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [inputs], maxlen=max_length_ch, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([ko_tokenizer.word_index['<start>']], 0)\n",
    "    for t in range(max_length_ko):\n",
    "        predictions, dec_hidden, attention_weights = decoder(\n",
    "            dec_input, dec_hidden, enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += ko_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if ko_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d823c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print(\"Input : %s\" % (sentence))\n",
    "    print(\"Predicted translation : {}\".format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')\n",
    "                                         ), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "translate(u'我迷失了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77856f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a4003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb799f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec72914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(train_df):\n",
    "    #글자단위 토큰화\n",
    "    ch_vocab, ko_vocab = set(), set()\n",
    "\n",
    "    for line in train_df['중국어']:\n",
    "        for c in line:\n",
    "            ch_vocab.add(c)\n",
    "\n",
    "    for line in train_df['한국어']:\n",
    "        for c in line:\n",
    "            ko_vocab.add(c)\n",
    "            \n",
    "    ch_vocab_size = len(ch_vocab) + 1  #94\n",
    "    ko_vocab_size = len(ko_vocab) + 1  #4837\n",
    "    \n",
    "    #set -> list(데이터 변경 용이한 자료구조로 변환)\n",
    "    ch_vocab = sorted(list(ch_vocab))\n",
    "    ko_vocab = sorted(list(ko_vocab))\n",
    "    \n",
    "    ch_to_index = dict([(c, i+1) for i, c in enumerate(ch_vocab)])\n",
    "    ko_to_index = dict([(c, i+1) for i, c in enumerate(ko_vocab)])\n",
    "    \n",
    "    #중국어 문장 인코딩\n",
    "    encoder_input = []\n",
    "    for li in train_df['중국어']:\n",
    "        t = []\n",
    "        for c in li:\n",
    "            t.append(ch_to_index[c])\n",
    "        encoder_input.append(t)\n",
    "        \n",
    "    #한국어 문장 인코딩\n",
    "    decoder_input = []\n",
    "    for li in train_df['한국어']:\n",
    "        t = []\n",
    "        for c in li:\n",
    "            t.append(ko_to_index[c])\n",
    "        decoder_input.append(t)   \n",
    "        \n",
    "    #번역되어 나올 한국어 문장 인코딩에서 '\\t' 제거\n",
    "    decoder_ko = []\n",
    "    for li in train_df['한국어']:\n",
    "        t = []\n",
    "        i = 0\n",
    "        for c in li:\n",
    "            if i > 0:\n",
    "                t.append(ko_to_index[c])\n",
    "            i += 1\n",
    "        decoder_ko.append(t)    \n",
    "     \n",
    "    #패딩\n",
    "    max_len_ch = 1689\n",
    "    max_len_ko = 373\n",
    "    \n",
    "    #문장 -> int -> padding\n",
    "    encoder_input = pad_sequences(encoder_input, maxlen=max_len_ch, padding='post')\n",
    "    decoder_input = pad_sequences(decoder_input, maxlen=max_len_ko, padding='post')\n",
    "    decoder_ko = pad_sequences(decoder_ko, maxlen=max_len_ko, padding='post') \n",
    "    \n",
    "    #문장들을 3차원 배열로 변환 : (encoder_input, decoder_input, decoder_target)\n",
    "    #encoder_input은 (문장 개수, 문장 최대 길이, 문자 종류 수) 형태의 3차원 배열로 중국어 문장의 one-hot 형식 벡터 데이터\n",
    "    #decoder_input은 (문장 개수, 문장 최대 길이, 문자 종류 수) 형태의 3차원 배열로 한국어 문장의 one-hot 형식 벡터 데이터\n",
    "    #decoder_ko은 decoder_input과 같지만, 하나의 time step만큼 offset, 즉, decoder_target[:, t, :] = decoder_input[:, t+1, :]\n",
    "    encoder_input = np_utils.to_categorical(encoder_input)\n",
    "    decoder_input = np_utils.to_categorical(decoder_input)\n",
    "    decoder_ko = np_utils.to_categorical(decoder_ko)\n",
    "    \n",
    "    return encoder_input, decoder_input, decoder_ko, ch_vocab_size, ko_vocab_size, index_to_ch, index_to_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c4d62",
   "metadata": {},
   "source": [
    "#### 데이터가 너무 많으면 한번에 토큰화할 수 없기 때문에,\n",
    "#### 데이터를 4000개씩 나누어 토큰화 > 모델학습 > 저장 > 전이학습 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[:4000]\n",
    "    \n",
    "encoder_input, decoder_input, decoder_ko, ch_vocab_size, ko_vocab_size, index_to_ch, index_to_ko = tokenize(df)\n",
    "\n",
    "#중국어 인코딩\n",
    "tmp_dict = dict((i,c ) for c , i in index_to_ch.items()) \n",
    "\n",
    "for i in tmp_dict:\n",
    "    try:\n",
    "        tmp_dict[i] = tmp_dict[i].encode('EUC_CN')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "index_to_ch = dict((i,c ) for c , i in tmp_dict.items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝 시 이전 상태의 실제값을 현재상태의 디코더 입력으로 해야함(예측값으로 하면 안됨)\n",
    "encoder_inputs = Input(shape=(None, ch_vocab_size), name='encoder_input')\n",
    "decoder_inputs = Input(shape=(None, ko_vocab_size ), name='decoder_input')\n",
    "\n",
    "# 인코더 LSTM 셀\n",
    "encoderLSTM = LSTM(units=256, return_state=True, name='encoderLSTM')    #return_state :인코더의 마지막 상태 정보를 디코더의 입력 상태 정보로 전달\n",
    "decoderLSTM = LSTM(units=256, return_sequences=True, return_state=True, name='decoderLSTM')\n",
    "\n",
    "# 인코더 LSTM셀의 입력 정의\n",
    "encoder_outputs, stateH, stateC = encoderLSTM(encoder_inputs) # _, 히든상태(위), 셀상태(오른쪽)\n",
    "encoder_state = [stateH, stateC] # 컨텍스트 벡터\n",
    "\n",
    "decoder_output, _, _ = decoderLSTM(decoder_inputs, initial_state=encoder_state)\n",
    "decoder_softmax = Dense(ko_vocab_size, activation=\"softmax\")\n",
    "decoder_output = decoder_softmax(decoder_output)\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(x=[encoder_input,decoder_input], y=decoder_ko, batch_size=64, epochs=50, callbacks=early_stopping)\n",
    "save_model(model, 'ch_to_ko.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c02352",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(train_df) // 2500):\n",
    "    df = train_df[i*(2500):(i+1)*2500]\n",
    "    \n",
    "    encoder_input, decoder_input, decoder_ko, ch_vocab_size, ko_vocab_size = tokenize(df)\n",
    "\n",
    "    model = load_model('ch_to_ko.h5')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model.fit(x=[encoder_input, decoder_input], y=decoder_ko, batch_size=64, epochs=3, callbacks=early_stopping)\n",
    "    save_model(model, 'ch_to_ko.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_state)\n",
    "\n",
    "ch_to_index = dict((i,c ) for c , i in index_to_ch.items()) \n",
    "ko_to_index = dict((i,c ) for c , i in index_to_ko.items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02382d23",
   "metadata": {},
   "source": [
    "## 기본 LSTM 기반의 seq2seq 모델을 이용해 decoder_ko 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e136bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_state_input_hidden = Input(shape=(256,))\n",
    "decoder_state_input_cell = Input(shape=(256,))\n",
    "decoder_state_input = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "\n",
    "decoder_output, state_hidden, state_cell = decoderLSTM(decoder_inputs, initial_state = decoder_state_input)\n",
    "decoder_state = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_softmax(decoder_output)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_inputs]+decoder_state_input, outputs=[decoder_output]+decoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19349d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(input_seq): \n",
    "    \n",
    "    state_value = encoder_model.predict(input_seq)\n",
    "    print('encoder_model의 예상 state_value :',np.shape(state_value))\n",
    "    \n",
    "    target_seq = np.zeros((1,1,ko_vocab_size))   #(1, 1, 1134)\n",
    "    target_seq[0,0,ko_to_index['\\t']] = 1      # 원핫인코딩\n",
    "    \n",
    "    stop = False\n",
    "    decoded_sent=\"\"\n",
    "    while not stop: # \"\\n\"문자를 만날때까지 반복\n",
    "        \n",
    "        output, h, c = decoder_model.predict([target_seq]+state_value)\n",
    "        # 예측값을 한국어 문자로 변환\n",
    "        token_index = np.argmax(output[0,-1,:]) \n",
    "        pred_char = index_to_ko[token_index]\n",
    "        \n",
    "        # 현시점 예측문자가 예측문장에 추가\n",
    "        decoded_sent += pred_char\n",
    "        \n",
    "        if (pred_char == \"\\n\" or len(decoded_sent) > 373):\n",
    "            stop = True\n",
    "            \n",
    "        # 현시점 예측결과가 다음 시점에 입력으로 \n",
    "        target_seq = np.zeros((1,1,ko_vocab_size))\n",
    "        target_seq[0,0,token_index] = 1\n",
    "        \n",
    "        # 현시점 상태를 다음 시점 상태로 사용\n",
    "        state_value = [h,c]\n",
    "    \n",
    "    return decoded_sent # 번역결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7419ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in [1,50,100,200,300]:\n",
    "    \n",
    "    input_seq = encoder_input[seq_index:seq_index+1]    # (1, 117, 2326)\n",
    "    decoded_seq = decode_seq(input_seq)\n",
    "    \n",
    "    print(\"입력문장:\", train_df['중국어'][seq_index])\n",
    "    print(\"정답:\", train_df['한국어'][seq_index][1:len(train_df['한국어'][seq_index])-1])   # \"\\t\", \"\\n\" 제거\n",
    "    print(\"번역기:\", decoded_seq[:len(decoded_seq)-1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d8038",
   "metadata": {},
   "source": [
    "## 모델이 잘 작동하는지 확인하기 위해 일부 문장 디코딩\n",
    "    -encoder_input을 샘플링해 decoder_target으로 변환해본다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('ch_to_ko')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "bbccb89b148dd9514aef483b7dbf5ef69a5110c405a551087bd813f1e5edc75f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
