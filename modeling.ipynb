{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f8f1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, save_model, load_model\n",
    "from keras.layers import Input, LSTM, Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c7a76",
   "metadata": {},
   "source": [
    "## 전체데이터(104만개) 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b08b75a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 : (1040000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>중국어</th>\n",
       "      <th>한국어</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>希望能迈开宝贵的脚步,为孩子们的闪耀梦想加油。</td>\n",
       "      <td>\\t부디 귀한 걸음 해주셔서 아이들의 반짝이는 꿈을 응원해 주시면 감사하겠습니다 .\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>根据童子军年度运营计划,将参加由韩国童子军首尔北部联盟江北地区联合会主办的夏令营。</td>\n",
       "      <td>\\t스카우트 연간운영계획에 따라 한국스카우트 서울북부연맹 강북지구연합회에서 주최하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>通过以制造者教育为基础的前进教育,培养学生可以准备幸福未来的积极的前进价值观,举行了乌克丽丽...</td>\n",
       "      <td>\\t메이커 교육에 기반을 둔 진로교육을 통해 , 학생들의 행복한 미래를 준비할 수 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>总是对周围的各种事物或现象感兴趣,用新的眼睛看待。</td>\n",
       "      <td>\\t주변의 여러 사물이나 현상에 늘 관심을 가지고 새로운 눈으로 바라봅니다 .\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>这时脖子后面或耳朵后面的头发也一定要梳。</td>\n",
       "      <td>\\t이때 목 뒤나 귀 뒤의 머리칼도 반드시 빗질해야 한다 .\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 중국어  \\\n",
       "0                            希望能迈开宝贵的脚步,为孩子们的闪耀梦想加油。   \n",
       "1          根据童子军年度运营计划,将参加由韩国童子军首尔北部联盟江北地区联合会主办的夏令营。   \n",
       "2  通过以制造者教育为基础的前进教育,培养学生可以准备幸福未来的积极的前进价值观,举行了乌克丽丽...   \n",
       "3                          总是对周围的各种事物或现象感兴趣,用新的眼睛看待。   \n",
       "4                               这时脖子后面或耳朵后面的头发也一定要梳。   \n",
       "\n",
       "                                                 한국어  \n",
       "0   \\t부디 귀한 걸음 해주셔서 아이들의 반짝이는 꿈을 응원해 주시면 감사하겠습니다 .\\n  \n",
       "1  \\t스카우트 연간운영계획에 따라 한국스카우트 서울북부연맹 강북지구연합회에서 주최하는...  \n",
       "2  \\t메이커 교육에 기반을 둔 진로교육을 통해 , 학생들의 행복한 미래를 준비할 수 ...  \n",
       "3      \\t주변의 여러 사물이나 현상에 늘 관심을 가지고 새로운 눈으로 바라봅니다 .\\n  \n",
       "4                \\t이때 목 뒤나 귀 뒤의 머리칼도 반드시 빗질해야 한다 .\\n  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_df.csv', index_col=0)\n",
    "\n",
    "print('전체 데이터 :', train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9ed299b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 373)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(li) for li in train_df['중국어']]) , max([len(li) for li in train_df['한국어']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed9477",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aec72914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(train_df):\n",
    "    #글자단위 토큰화\n",
    "    ch_vocab, ko_vocab = set(), set()\n",
    "\n",
    "    for line in train_df['중국어']:\n",
    "        for c in line:\n",
    "            ch_vocab.add(c)\n",
    "\n",
    "    for line in train_df['한국어']:\n",
    "        for c in line:\n",
    "            ko_vocab.add(c)\n",
    "            \n",
    "    ch_vocab_size = len(ch_vocab) + 1  #94\n",
    "    ko_vocab_size = len(ko_vocab) + 1  #4837\n",
    "    \n",
    "    #set -> list(데이터 변경 용이한 자료구조로 변환)\n",
    "    ch_vocab = sorted(list(ch_vocab))\n",
    "    ko_vocab = sorted(list(ko_vocab))\n",
    "    \n",
    "    ch_to_index = dict([(c, i+1) for i, c in enumerate(ch_vocab)])\n",
    "    ko_to_index = dict([(c, i+1) for i, c in enumerate(ko_vocab)])\n",
    "    \n",
    "    #중국어 문장 인코딩\n",
    "    encoder_input = []\n",
    "    for li in train_df['중국어']:\n",
    "        t = []\n",
    "        for c in li:\n",
    "            t.append(ch_to_index[c])\n",
    "        encoder_input.append(t)\n",
    "        \n",
    "    #한국어 문장 인코딩\n",
    "    decoder_input = []\n",
    "    for li in train_df['한국어']:\n",
    "        t = []\n",
    "        for c in li:\n",
    "            t.append(ko_to_index[c])\n",
    "        decoder_input.append(t)   \n",
    "        \n",
    "    #번역되어 나올 한국어 문장 인코딩에서 '\\t' 제거\n",
    "    decoder_ko = []\n",
    "    for li in train_df['한국어']:\n",
    "        t = []\n",
    "        i = 0\n",
    "        for c in li:\n",
    "            if i > 0:\n",
    "                t.append(ko_to_index[c])\n",
    "            i += 1\n",
    "        decoder_ko.append(t)    \n",
    "     \n",
    "    #패딩\n",
    "    max_len_ch = 1689\n",
    "    max_len_ko = 373\n",
    "    \n",
    "    #문장 -> int -> padding\n",
    "    encoder_input = pad_sequences(encoder_input, maxlen=max_len_ch, padding='post')\n",
    "    decoder_input = pad_sequences(decoder_input, maxlen=max_len_ko, padding='post')\n",
    "    decoder_ko = pad_sequences(decoder_ko, maxlen=max_len_ko, padding='post') \n",
    "    \n",
    "    #문장들을 3차원 배열로 변환 : (encoder_input, decoder_input, decoder_target)\n",
    "    #encoder_input은 (문장 개수, 문장 최대 길이, 문자 종류 수) 형태의 3차원 배열로 중국어 문장의 one-hot 형식 벡터 데이터\n",
    "    #decoder_input은 (문장 개수, 문장 최대 길이, 문자 종류 수) 형태의 3차원 배열로 한국어 문장의 one-hot 형식 벡터 데이터\n",
    "    #decoder_ko은 decoder_input과 같지만, 하나의 time step만큼 offset, 즉, decoder_target[:, t, :] = decoder_input[:, t+1, :]\n",
    "    encoder_input = np_utils.to_categorical(encoder_input)\n",
    "    decoder_input = np_utils.to_categorical(decoder_input)\n",
    "    decoder_ko = np_utils.to_categorical(decoder_ko)\n",
    "    \n",
    "    return encoder_input, decoder_input, decoder_ko, ch_vocab_size, ko_vocab_size, index_to_ch, index_to_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c4d62",
   "metadata": {},
   "source": [
    "#### 데이터가 너무 많으면 한번에 토큰화할 수 없기 때문에,\n",
    "#### 데이터를 4000개씩 나누어 토큰화 > 모델학습 > 저장 > 전이학습 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "af4a48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[:4000]\n",
    "    \n",
    "encoder_input, decoder_input, decoder_ko, ch_vocab_size, ko_vocab_size, index_to_ch, index_to_ko = tokenize(df)\n",
    "\n",
    "#중국어 인코딩\n",
    "tmp_dict = dict((i,c ) for c , i in index_to_ch.items()) \n",
    "\n",
    "for i in tmp_dict:\n",
    "    try:\n",
    "        tmp_dict[i] = tmp_dict[i].encode('EUC_CN')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "index_to_ch = dict((i,c ) for c , i in tmp_dict.items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bf7b1113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, None, 1048)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, None, 598)]  0           []                               \n",
      "                                                                                                  \n",
      " encoderLSTM (LSTM)             [(None, 256),        1336320     ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoderLSTM (LSTM)             [(None, None, 256),  875520      ['decoder_input[0][0]',          \n",
      "                                 (None, 256),                     'encoderLSTM[0][1]',            \n",
      "                                 (None, 256)]                     'encoderLSTM[0][2]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, None, 598)    153686      ['decoderLSTM[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,365,526\n",
      "Trainable params: 2,365,526\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝 시 이전 상태의 실제값을 현재상태의 디코더 입력으로 해야함(예측값으로 하면 안됨)\n",
    "encoder_inputs = Input(shape=(None, ch_vocab_size), name='encoder_input')\n",
    "decoder_inputs = Input(shape=(None, ko_vocab_size ), name='decoder_input')\n",
    "\n",
    "# 인코더 LSTM 셀\n",
    "encoderLSTM = LSTM(units=256, return_state=True, name='encoderLSTM')    #return_state :인코더의 마지막 상태 정보를 디코더의 입력 상태 정보로 전달\n",
    "decoderLSTM = LSTM(units=256, return_sequences=True, return_state=True, name='decoderLSTM')\n",
    "\n",
    "# 인코더 LSTM셀의 입력 정의\n",
    "encoder_outputs, stateH, stateC = encoderLSTM(encoder_inputs) # _, 히든상태(위), 셀상태(오른쪽)\n",
    "encoder_state = [stateH, stateC] # 컨텍스트 벡터\n",
    "\n",
    "decoder_output, _, _ = decoderLSTM(decoder_inputs, initial_state=encoder_state)\n",
    "decoder_softmax = Dense(ko_vocab_size, activation=\"softmax\")\n",
    "decoder_output = decoder_softmax(decoder_output)\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a10d59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.1127WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 169s 4s/step - loss: 3.1127\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.2821WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 189s 5s/step - loss: 1.2821\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.1769WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 204s 5s/step - loss: 1.1769\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.2813WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 195s 5s/step - loss: 1.2813\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.2869WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 189s 5s/step - loss: 1.2869\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.8179WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 189s 5s/step - loss: 1.8179\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.0270WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 191s 5s/step - loss: 1.0270\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.0911WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 191s 5s/step - loss: 2.0911\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.1776WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 190s 5s/step - loss: 1.1776\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.9156WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 193s 5s/step - loss: 0.9156\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8439WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 189s 5s/step - loss: 0.8439\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8238WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 190s 5s/step - loss: 0.8238\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8138WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 192s 5s/step - loss: 0.8138\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8073WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 193s 5s/step - loss: 0.8073\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8024WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 195s 5s/step - loss: 0.8024\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7979WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 199s 5s/step - loss: 0.7979\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7936WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 197s 5s/step - loss: 0.7936\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 193s 5s/step - loss: 0.7900\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7873WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 475s 12s/step - loss: 0.7873\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7836  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 23313s 229s/step - loss: 0.7836\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7817WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 195s 5s/step - loss: 0.7817\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7779WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 197s 5s/step - loss: 0.7779\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7742WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 194s 5s/step - loss: 0.7742\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7712WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 195s 5s/step - loss: 0.7712\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7681WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 193s 5s/step - loss: 0.7681\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7650WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 194s 5s/step - loss: 0.7650\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7613WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 196s 5s/step - loss: 0.7613\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7574WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 193s 5s/step - loss: 0.7574\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7534WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 190s 5s/step - loss: 0.7534\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7490WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 195s 5s/step - loss: 0.7490\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7445WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 193s 5s/step - loss: 0.7445\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7399WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 196s 5s/step - loss: 0.7399\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7347WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 195s 5s/step - loss: 0.7347\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7289WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 191s 5s/step - loss: 0.7289\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7230WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 193s 5s/step - loss: 0.7230\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7164WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 191s 5s/step - loss: 0.7164\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7096WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 192s 5s/step - loss: 0.7096\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7025WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 195s 5s/step - loss: 0.7025\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6952 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 2128s 54s/step - loss: 0.6952\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6870WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 206s 5s/step - loss: 0.6870\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6790WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 203s 5s/step - loss: 0.6790\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6705WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 200s 5s/step - loss: 0.6705\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6616WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 206s 5s/step - loss: 0.6616\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6532WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 212s 5s/step - loss: 0.6532\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6441WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 214s 5s/step - loss: 0.6441\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6354WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 209s 5s/step - loss: 0.6354\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6278WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 213s 5s/step - loss: 0.6278\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6191WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 209s 5s/step - loss: 0.6191\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7504WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 212s 5s/step - loss: 0.7504\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7095WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "40/40 [==============================] - 211s 5s/step - loss: 0.7095\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(x=[encoder_input,decoder_input], y=decoder_ko, batch_size=64, epochs=50, callbacks=early_stopping)\n",
    "save_model(model, 'ch_to_ko.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c02352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, None, 2088), found shape=(None, 108, 2148)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1012/3798991434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_input_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_target_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ch_to_ko.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, None, 2088), found shape=(None, 108, 2148)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(train_df) // 2500):\n",
    "    df = train_df[i*(2500):(i+1)*2500]\n",
    "    \n",
    "    encoder_input, decoder_input, decoder_ko, ch_vocab_size, ko_vocab_size = tokenize(df)\n",
    "\n",
    "    model = load_model('ch_to_ko.h5')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model.fit(x=[encoder_input, decoder_input], y=decoder_ko, batch_size=64, epochs=3, callbacks=early_stopping)\n",
    "    save_model(model, 'ch_to_ko.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "498a5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_state)\n",
    "\n",
    "ch_to_index = dict((i,c ) for c , i in index_to_ch.items()) \n",
    "ko_to_index = dict((i,c ) for c , i in index_to_ko.items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a23297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, None, 2088)]      0         \n",
      "                                                                 \n",
      " encoderLSTM (LSTM)          [(None, 256),             2401280   \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,401,280\n",
      "Trainable params: 2,401,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02382d23",
   "metadata": {},
   "source": [
    "## 기본 LSTM 기반의 seq2seq 모델을 이용해 decoder_ko 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74e136bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_state_input_hidden = Input(shape=(256,))\n",
    "decoder_state_input_cell = Input(shape=(256,))\n",
    "decoder_state_input = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "\n",
    "decoder_output, state_hidden, state_cell = decoderLSTM(decoder_inputs, initial_state = decoder_state_input)\n",
    "decoder_state = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_softmax(decoder_output)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_inputs]+decoder_state_input, outputs=[decoder_output]+decoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e19349d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_input (InputLayer)     [(None, None, 1035)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " decoderLSTM (LSTM)             [(None, None, 256),  1323008     ['decoder_input[0][0]',          \n",
      "                                 (None, 256),                     'input_7[0][0]',                \n",
      "                                 (None, 256)]                     'input_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,323,008\n",
      "Trainable params: 1,323,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "440c15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(input_seq): \n",
    "    \n",
    "    state_value = encoder_model.predict(input_seq)\n",
    "    print('encoder_model의 예상 state_value :',np.shape(state_value))\n",
    "    \n",
    "    target_seq = np.zeros((1,1,ko_vocab_size))   #(1, 1, 1134)\n",
    "    target_seq[0,0,ko_to_index['\\t']] = 1      # 원핫인코딩\n",
    "    \n",
    "    stop = False\n",
    "    decoded_sent=\"\"\n",
    "    while not stop: # \"\\n\"문자를 만날때까지 반복\n",
    "        \n",
    "        output, h, c = decoder_model.predict([target_seq]+state_value)\n",
    "        # 예측값을 한국어 문자로 변환\n",
    "        token_index = np.argmax(output[0,-1,:]) \n",
    "        pred_char = index_to_ko[token_index]\n",
    "        \n",
    "        # 현시점 예측문자가 예측문장에 추가\n",
    "        decoded_sent += pred_char\n",
    "        \n",
    "        if (pred_char == \"\\n\" or len(decoded_sent) > 373):\n",
    "            stop = True\n",
    "            \n",
    "        # 현시점 예측결과가 다음 시점에 입력으로 \n",
    "        target_seq = np.zeros((1,1,ko_vocab_size))\n",
    "        target_seq[0,0,token_index] = 1\n",
    "        \n",
    "        # 현시점 상태를 다음 시점 상태로 사용\n",
    "        state_value = [h,c]\n",
    "    \n",
    "    return decoded_sent # 번역결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ed7419ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_10\" is incompatible with the layer: expected shape=(None, None, 2088), found shape=(None, 1689, 1843)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11276/540212830.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m# (1, 117, 2326)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdecoded_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"입력문장:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'중국어'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11276/1869718604.py\u001b[0m in \u001b[0;36mdecode_seq\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mstate_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder_model의 예상 state_value :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\yeonok\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_10\" is incompatible with the layer: expected shape=(None, None, 2088), found shape=(None, 1689, 1843)\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [1,50,100,200,300]:\n",
    "    \n",
    "    input_seq = encoder_input[seq_index:seq_index+1]    # (1, 117, 2326)\n",
    "    decoded_seq = decode_seq(input_seq)\n",
    "    \n",
    "    print(\"입력문장:\", train_df['중국어'][seq_index])\n",
    "    print(\"정답:\", train_df['한국어'][seq_index][1:len(train_df['한국어'][seq_index])-1])   # \"\\t\", \"\\n\" 제거\n",
    "    print(\"번역기:\", decoded_seq[:len(decoded_seq)-1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d8038",
   "metadata": {},
   "source": [
    "## 모델이 잘 작동하는지 확인하기 위해 일부 문장 디코딩\n",
    "    -encoder_input을 샘플링해 decoder_target으로 변환해본다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
