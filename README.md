
## seq2seq를 활용한 중국어 번역모델 만들기

#### 1. 데이터
  + [AI HUB 한국어-중국어 번역 말뭉치 데이터(사회과학)](https://aihub.or.kr/aidata/30721)
  + [AI HUB 한국어-중국어 번역 말뭉치 데이터(기술과학)](https://aihub.or.kr/aidata/30722)

#### 2. 모델
seq2seq

  + RNN의 경우 문장이 길어질수록 앞의 정보가 뒤로 충분히 전달되지 못하기 때문에, 최대 길이가 100글자가 넘는 문장을 처리하기에 부적합  
  + LSTM, GRU 또한 RNN기반으로 이런 장기의존성 문제를 갖고 있음  
  + 인코더-디코더를 이용해 장기의존성 문제를 해결한 Attention 모델 활용  
    =>그 중에서도 seq2seq는 2014년 발표되어 챗봇과 기계번역에 많이 쓰이는 모델로,   
      입력 시퀀스와 출력 시퀀스를 각각 입력 문장과 번역 문장으로 만들면 번역기를 만들 수 있음
      
      
#### 3. 더 진행해야 할 점

  + 전체 데이터 학습
  + 학습된 모델로 번역 결과 출력
  + 웹페이지 완성, 모델과 연결, 배포
